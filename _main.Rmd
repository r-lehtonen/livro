--- 
title: "Análises de Dados com R"
author: "Ricardo Lehtonen R. de Souza"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [book.bib]
url: https://bookdown.org/ricardo_lehtonen/analise
cover-image: capa.png
description: |
  Nesse livro trazemos uma introdução à analise de dados com R, começando do básico, com a instalação do R, passando pelos objetos do R, gráficos, estatística e mais algumas aplicações.
link-citations: yes
github-repo:
isbn: 978-65-00-76198-6
---

# Prefácio {-}

Na pesquisa científica, a análise de dados é uma parte fundamental e o R é uma linguagem que possibilita a fazer as mais diversas análises, não é apenas uma ferramenta estatística.  
O R é um software livre e uma grande comunidade trabalha aperfeiçoando a ferramenta e todo dia temos novidades, tornando o aprendizado muito dinâmico.
Há alguns anos, achei importante estimular o uso do R pelos discentes do Programa de Pós-Graduação em Genética da Universidade Federal do Paraná (UFPR), assim reformulei a disciplina de Bioinformática, introduzindo o R. Na primeira oferta da disciplina refomulada, trouxe minha amiga, a Dra Kelly Nunes, para ministrar a disciplina. De lá para cá já foram muitos discentes que passaram pela disciplina e fico contente ao ver eles utilizando o R em suas análises.
Mais recentemente, havia uma demanda para aprender R por parte do curso de Biomedicina da UFPR, então propus criar uma disciplina optativa para a graduação, a qual foi ofertada inicialmente para os cursos de Biomedicina e Ciências Biológicas.
Esse livro surgiu da necessidade de organizar o material didático que uso nessas disciplinas, de forma a facilitar a atualização das informações e disponibilização para os discentes.  
 

ISBN: 978-65-00-76198-6


<!--chapter:end:index.Rmd-->

---
editor_options: 
  markdown: 
    wrap: 72
---

# Introdução

## O que é R

O R é uma linguagem de alto nível e um ambiente para análise de dados e
geração de gráficos. Alguns pensam que o R é apenas um pacote
estatístico, no entanto, o R é muito mais do que isso, embora a parte
estatística seja um dos pontos fortes do R.

O R tem código aberto, ou seja, pode ser modificado, aprimorado a
qualquer momento por qualquer usuário. Ele foi criado em 1991, na Nova
Zelândia (University of Auckland) por Ross Ihaka e Robert Gentleman.

O R está estruturado em duas partes principais, a base do R e os pacotes
que podemos ir instalando.

Existem milhares de pacotes do R para as mais diversas funções, que
encontramos no repositórios:

-   CRAN package repository.
-   Bioconductor.

Para saber como citar o R, basta usar o seguinte comando:

```{r 01- citacao, echo=TRUE, message=FALSE, warning=FALSE}
citation()
```

Ajuda sobre o R

O R tem um sistema de ajuda bastante elaborado que lhe permitirá obter
muita informação extra sobre a linguagem, bem como muitos outros
aspectos. Usando a interface gráfica (RStudio), podemos obter ajuda
através do menu Help Se pretende simplesmente obter ajuda sobre uma
função em particular do R, a forma mais simples é usar a função help():

```{r 01- help, message=FALSE, warning=FALSE}
help(sqrt)
```

Além disso, disso existem muito material disponível na internet, abaixo
estão alguns exemplos:

Stackoverflow <https://stackoverflow.com/questions/tagged/r>

Rdocumentation <https://www.rdocumentation.org/>

Rseek <https://rseek.org/>

R-bloggers <https://www.r-bloggers.com/>

## Instalação

O primeiro passo é instalar o R. Podemos baixar a última versão em
<https://cran.r-project.org/> Nesse mesmo site temos a lista de pacotes
disponíveis. Quando atualizamos o R, temos que instalar novamente os
pacotes que tínhamos na versão anterior. Para facilitar, temos um pacote
chamado installr, que permite atualizar o R, copiar e atualizar os
pacotes para a nova versão.

## RStudio

Apesar de podermos utilizar o R diretamente no console, o uso da
interface gráfica RStudio facilta muito o uso do R. Podemos baixar o
RStudio de <https://posit.co/downloads/>

No seguinte link tem dicas de como usar o RStudio:
<https://posit.co/wp-content/uploads/2022/10/rstudio-ide-1.pdf>

## Objetos do R

O R é uma linguagem baseada em objetos, de forma que as coisas que
usamos ficam na memória do computador sob a forma de um objeto. Esses
objetos recebem um nome e podem armazenar diferentes tipos de
informações como números, texto, vetores, matrizes, expressões, etc.

Para armazenar algo num objeto usamos o operador de atribuição: **\<-**

Exemplo:

```{r 01 -operador}
x1 <- 0.6
```

Para ver o conteúdo do objeto:

```{r 01- objeto}
x1
```

-   O [1] que aparece antes do número guardado no objeto mostra o número
    da linha do conteúdo do objeto.
-   A operação de atribuição é destrutiva no sentido que ao atribuir um
    novo valor a um objeto existente, vamos perder o conteúdo que ele
    estava armazenado anteriormente.

Também podemos atribuir expressões numéricas a objetos. O resultado de
tal operação é o de que o resultado do cálculo da expressão e não a
expressão propriamente dita:

```{r 01- operacoes}
x2 <- 15
x3 <- x2^3
x3
```

-   Os objetos que criamos ficam na memória do computador e se quisermos
    podemos apagar um objeto.\
-   Podemos ver quais os objetos atualmente na memória do computador
    usando as funções ls() ou objects().
-   Se não necessitamos de algum dos objetos podemos apagá-lo com a
    função rm()\
-   No RStudio, podemos ver os objetos na aba environment e, se
    quisermos apagar todos os objetos, podemos clicar no ícone da
    vassoura, nesta mesma aba.

## Nomes dos objetos do R

-   Para darmos nome para os objetos podemos usar letras maiúsculas ou
    minúsculas, os dígitos 0 a 9 (exceto no início do nome), o ponto
    final e não podemos usar espaços.
-   Lembre-se de que o R é sensível às letras maiúsculas / minúsculas,
    por exemplo, o nome **dados** é diferente de **Dados**.

## Vetores

-   Um dos principais objetos do R para é o vetor.

-   Um vetor é uma estrutura de dados que permite armazenar um conjunto
    de valores do mesmo tipo (por exemplo números) sob um mesmo nome.

-   Esses elementos podem depois ser acessados individualmente usando um
    esquema de indexação.

-   Este tipo de estrutura de dados é bastante útil quando pretendemos
    armazenar várias coisas relacionadas.

-   Todos os vetores em R tem um modo e um tamanho.

-   O modo determina o tipo de valores guardado no vetor.

-   Em R podemos ter vetores com modo character, logical, numeric e
    complex.

-   Ou seja, podemos ter vetores para armazenar os seguintes tipos de
    dados: conjuntos de caracteres, valores lógicos (F ou T ou FALSE ou
    TRUE), números inteiros ou reais, e números complexos

-   Para criar vetores usamos a função c() e separamos os elementos por
    vírgulas. Por exemplo, para armazenar um conjunto de notas:

```{r 01- vetor 1}
notas <- c(4, 7, 10, 9.5, 7.5)
notas
```

-   Comprimento e modo do vetor:

```{r 01- vetor 2}
length(notas)
mode(notas)
```

-   Ao criar um vetor temos que cuidar para que todos os elementos sejam
    do mesmo tipo (modo).
-   Se criarmos um vetor com tipos diferentes, o R vai forçá-los a ser
    do mesmo tipo, como no exemplo a seguir:

```{r 01- vetor 3}
notas2 <- c(6, 10, 7.5, 9, 8, "nc")
notas2
```

O vetor criado será do tipo caracter. No exemplo anterior coloquei nc
para quem não compareceu. Para resolver isso temos outra alternativa,
que veremos a seguir.

-   No R temos um elemento especial que é o NA.
-   Este valor representa um valor desconhecido.
-   Por exemplo, se temos a idade de pacientes guardados num vetor, mas
    não temos essa informação de um indivíduo, podemos criar esse vetor:

```{r 01- vetor 4}
idade<- c(23, 45, NA, 34)
idade
```

-   Os elementos de um vetor podem ser acessados através de um índice:

```{r 01- vetor 5}
idade[2]
```

-   O R permite criar vetores vazios usando a função vector():

```{r 01- vetor 6}
x4 <- vector()
```

-   O tamanho de um vetor existente pode ser alterado atribuindo mais
    elementos a índices até agora inexistentes:

```{r 01- vetor 7}
x4[3] <- 60
x4
```

## Operações com Vetores

-   A linguagem R permite vetorizar a maioria das suas funções. Por
    exemplo, a função sqrt() que serve para calcular raíz quadrada:

```{r 01- vetor 8}
x5 <- c(9, 16, 25, 36, 49)
x5 <- sqrt(x5)
x5
```

O R pode ser usado para fazer operações aritméticas envolvendo vetores:

```{r 01- vetor 9}
x6 <- c(5, 10, 15)
x7 <- c(20, 20, 20)
x6 + x7
```

-   No entanto, se os vetores tiverem tamanhos diferentes, o R vai
    reciclar os valores do vetor mais curto até este atingir o tamanho
    do maior. Por exemplo:

```{r 01- vetor 10}
x8 <- c(5, 10, 15, 20)
x9 <- c(5, 10)
x8 + x9
```

## Fatores

-   Quando temos variáveis categóricas, podemos usar outro tipo de
    objeto do R, o fator.
-   Cada fator tem um conjunto de níveis. Vamos ver um exemplo.
    Suponhamos que pretendemos guardar o genótipo de 10 indivíduos em um
    vetor:

```{r 01- fator 1}
gt <- c("CC", "CT", "CC", "CC", "CT", "TT", "CT", "CT", "TT", "CT")
gt
```

Para transformar esse vetor de caracteres em um fator, usamos a função
**factor**:

```{r 01- fator 2}
gt <- factor(gt)
gt
```

-   Suponha agora que temos 4 indivíduos cujo genótipo pretendemos
    armazenar.
-   Imagine que por coincidência não aparece o genótipo TT.
-   Se pretendemos que o fator resultante mantenha os 3 níveis
    possíveis, teremos que fazer:

```{r 01- fator 3}
gt2 <- factor(c("CC", "CT", "CT", "CT"), levels = c("CC", "CT","TT"))
gt2
```

Podemos usar a função **table** contar o número de ocorrências de cada
valor (nível):

```{r 01- fator 4}
table(gt)
```

```{r 01- fator 5}
table(gt2)
```

-   Para fatores do mesmo tamanho usamos a função table() para fazer
    tabulações cruzadas de dois fatores.
-   Usando o fator gt, com os genótipos dos indivíduos, e um novo fator
    com os grupos (caso x controle), podemos fazer uma tabulação cruzada
    entre genótipos e e grupo:

```{r 01- fator 6}
grupo <- factor(c("caso", "caso", "controle", "controle", "caso", "caso", "caso", "controle", "caso", "controle"))
table(gt, grupo)
```

-   Também é possível obter frequências marginais e relativas:

```{r 01- fator 7}
tabela <- table(gt, grupo)
margin.table(tabela, 1)
```

Frequências relativas com a função prop.table():

```{r 01- fator 8}
prop.table(tabela, 1)
```

```{r 01- fator 9}
prop.table(tabela, 2)
```

```{r 01- fator 10}
prop.table(tabela)
```

## Matrizes

-   Para armazenar os dados em estruturas com mais do que uma dimensão
    usamos as matrizes arranjam a informação em duas dimensões.

-   Para criar uma matriz usamos uma função específica para isso. Se
    quisermos criar uma matriz de 3 linhas e 4 colunas:

```{r 01- matrizes 1}
dados <- matrix(c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120), 3, 4)
dados
```

-   Os números são colocados na matriz por coluna, mas se quisermos
    preencher a matriz por linhas da seguinte forma:

```{r 01- matrizes 2}
dados2 <- matrix(c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, 120), 3, 4, byrow = T)
dados2
```

-   Nas matrizes podemos dar nomes para linhas e colunas. Vejamos como
    fazer isso no exemplo anterior:

```{r 01- matrizes 3}
rownames(dados) <- c("caso1", "caso2", "caso3")
colnames(dados) <- c("var1", "var2", "var3", "var4")
dados
```

-   Podemos acessar elementos individuais das matrizes usando um esquema
    de indexação:

```{r 01- matrizes 4}
dados[2, 2]

```

Ou então, usando os nomes:

```{r 01- matrizes 5}
dados["caso1", "var2"] 
```

-   As funções cbind() e rbind() podem ser usadas para juntar dois ou
    mais vetores ou matrizes, por colunas ou por linhas,
    respectivamente, como podemos ver a seguir:

```{r 01- matrizes 6}
ex1 <- c(15, 25, 65, 75)
ex2<-c(10, 20, 30, 40)

m1<-cbind(ex1, ex2)
m1
m2<-rbind(ex1, ex2)
m2
```

-   As regras aritméticas também se aplicam as matrizes.

```{r 01- matrizes 7}
m1 * 3

```

## Listas

-   Outro objeto que temos é a lista. Na lista podemos colocar coisas
    variadas, que não precisam ser do mesmo tipo, modo ou tamanho.
-   Os componentes de uma lista em R são sempre numerados e podem também
    ter um nome associados a eles.\
-   Por exemplo, podemos criar uma lista com vários objetos criados
    anteriormente:

```{r 01- listas 1}
lt <- list(idade, gt, dados)
lt[[1]] 
```

## Data frame

-   Um data frame é um objeto do R usado para guardar tabelas de dados
    de um problema qualquer.
-   É muito semelhante a uma matriz, mas as suas colunas tem nomes e
    podem conter dados de tipo diferente, diferente da matriz.
-   Um data frame pode ser visto como uma tabela de uma base de dados,
    em que cada linha corresponde a um registro (linha) da tabela. Cada
    coluna corresponde às propriedades (campos) a serem armazenadas para
    cada registro da tabela.

```{r 01- listas 2}
dados2 <- data.frame(idade = c(50, 45, 30, 20), genotipo = c("CC", "CT", "CT", "TT"), sexo = c("M", "F", "M", "F"))
dados2
```

## Sequências

-   Para gerar dados sequenciais, em vez digitar os valores, podemos
    gerar sequências de várias de formas.
-   Por exemplo, para criar um vetor com os números de 1 a 100, em vez
    de os escrevermos todos, podemos usar:

```{r 01- sequencias 1}
x <- 1:100
```

-   Exemplos:

```{r 01- sequencias 2}
seq(from = 1, to = 5, length = 4)
seq(from = 1, to = 5, length = 2)
seq(length = 10, from = -2, by = 0.2)
letters[1:10]
```

-   Uma outra função bastante útil para gerar sequências é a função
    rep():

```{r 01- sequencias 3}
rep(5, 10)
rep("sim", 3)
rep(1:3, 2)
```

Para ler um pouco mais sobre o assunto: [@torgo2011introduccao]

<!--chapter:end:01-intro.Rmd-->

---
editor_options: 
  markdown: 
    wrap: 72
---

# Carregar e manipular dados

Dados  
Uma etapa muito importante é planejar as planilhas de dados. Se os dados estiverem bem organizados, isso vai poupar muito tempo.

Como os dados devem estar organizados: os casos nas linhas e as variáveis nas colunas.

Os dados podem estar em planilhas do excel ou em arquivos de texto. Vamos ver como carregar esses dados.

## Ler arquivos txt e csv

Para ler um arquivo txt usamos a função read.table. No exemplo abaixo, o arquivo iris.txt está dentro pasta dados:

```{r 02- txt}
dados<-read.table("dados/iris.txt", head=T, sep = ",")

head(dados)
tail(dados)
```

Onde **head=T** indica que os dados tem uma linha de cabeçalho e **sep** define o separador das variáveis, nesse caso é a vírgula.  
Use **help("read.table")** para ver outros parâmetros.

Podemos ver as primeiras linhas do objeto **head** e as últimas linhas com **tail**.

## Ler arquivos xlsx

Instale e ative o pacote openxlsx. Temos duas maneiras de instalar um pacote. No RStudio, podemos clicar em **Install** na aba **Packages** e então digitar o nome do pacote a ser instalado. Ou podemos usar a função install.packages(), especificando o nome do pacote dentro do parêntesis.  
Sempre que formos utilizar um pacote, precisamos ativá-lo. Também temos duas maneiras de fazer isso. A primeira, usando o RStudio, na aba **Packages** procuramos o pacote e clicamos na caixa de seleção. A segunda maneira, a qual recomendo usar, é com a função **library()**. Dessa forma, a ativação já estará no script e não corremos o risco de esquecer de ativar o pacote.
O pacote openxlsx permite ler e gravar arquivo xlsx, como no exemplo abaixo:  


```{r 02- xlsx}
library(openxlsx)
dados2<-read.xlsx("dados/pinguim.xlsx", sheet = 1, colNames = T)
head(dados2)
```
Onde sheet especifica qual planilha do arquivo xlsx deve ser lida e colNames = T indica que na primeira linha estão os títulos das colunas.
Podemos definir outros parâmetros também, como por exemplo, especificar em qual linha começar a ler os dados com startRow =, ou definir quais colunas pegar com cols =.

Também é possível usar a opção do RStudio para importar dados para isso, na aba environment, clique em import Dataset tem opções de importar dados do texto, do excel, do SPSS e outros formatos.

## Gravar arquivos txt e xlsx

Gravar arquivos

Podemos gravar um arquivo txt ou xlsx

```{r 02- write}
write.table(dados, file="dados/flor.txt", quote=F, row.names = F,append=F)

write.xlsx(dados, "dados/flor.xlsx", sheetName="Plan1", colNames=T, rowNames=F,append=F)
```

## Manipulação de dados (R base)

Com a função **summary** podemos ver um resumo sobre uma variável:

```{r 02- summary}
summary(dados$sepal_l)
```

Para especificar a variável, usamos o nome do objeto seguido de \$ e o nome da coluna

Podemos ver um resumo de todas as variáveis:

```{r 02- summary 2}
summary(dados)
```

Podemos ver as características das variáveis usando a função **str**:

```{r 02- str}
str(dados)
```

Indexação

Podemos usar indexação para acessar dados específicos.

```{r 02- indexacao}
dados[2,3] # [linha, coluna]
dados[,3] # todos os dados da coluna 3
dados[2,] # todos os dados da linha 2
dados$sepal_w # todos os dados da coluna sepal_w
colnames(dados) # nomes das colunas
```

Selecionando dados.   
Como exemplo, vamos selecionar apenas as linhas que
correspondem à espécie *Iris virginica*. Os dados referentes à espécie estão na variável **class**.

```{r 02- filtro}
virginica<- dados[dados$class=="Iris-virginica",]
```

A indexação é linha, coluna. A vírgula no final sem nada depois significa que é para pegar todos as colunas.

Se quisermos pegar só a coluna 3 usamos assim:

```{r 02- filtro 2}
petal_virginica<-dados[dados$class=="Iris-virginica", 3]
```

Podemos selecionar algumas colunas. No exemplo abaixo selecionamos as colunas 3 a 5:

```{r 02- selecionar}
dados3<-dados2[, c(3:5)]
```

Como a indexação é linha, coluna, dentro dos [] tem uma vírgula e nada antes da vírgula, isso significa pegar todas as linhas, depois da vírgula está especificado para pegar as colunas de 3 a 5.

Criando uma coluna

Criando uma coluna chamada índice com NA:

```{r 02- coluna}
dados$indice<-NA 
dados$indice
```

Adicionando dados:

```{r 02- dados}
dados$indice<-(dados$sepal_l*dados$sepal_w)
head(dados)
```

Operadores

Podemos usar operadores:

igual ==   
diferente !=   
x ou y =\> x \| y   
x e y =\> x & y  


Então, além de selecionar um parâmetro da variável class, aqui também selecionamos por outro parâmetro da variável sepal_l, usando o operador &.

```{r 02- operadors}
virginica2<- dados[dados$class=="Iris-virginica" & dados$sepal_l>6.5,]
virginica2$sepal_l
```

## Transformação de dados

Muitos valores das características tem escalas muito diferentes. Isso pode gerar dificuldades para algoritmos que usam todos esses valores para compor um valor único de comparação. Para resolver isso pode ser utilizada a normalização ou conversão de dados.

## Técnicas de normalização

Min-max: altera valores extremos e organiza os internos dentro de um novo intervalo. 
  
  
v'=((v-min(v))/(max(v) - min(v)))\*(maxnovo - minnovo) +
minnovo

Para exemplificar, vamos transformar a variável body_mass_g em uma escala de 0 a 1 e armazenar o resultado em uma nova variável chamada body_norm:

```{r 02- transformacao}
maxnovo<-1
minnovo<-0
dados2$body_norm<-NA
dados2$body_norm<-((dados2$body_mass_g-(min(dados2$body_mass_g, na.rm = T)))/(max(dados2$body_mass_g,na.rm = T) - (min(dados2$body_mass_g,na.rm = T)))*(maxnovo - minnovo) + minnovo)
dados2$body_norm
hist(dados2$body_norm)
```

Outra opção é o Z-score, no qual os valores são reorganizados pela média e desvio-padrão do conjunto original:  
v1=(v - média(v))/desvio padrão (v)

Vamos usar a mesma variável e transformar para Z-score:

```{r 02- transformacao 2}
dados2$body_norm2<-NA
dados2$body_norm2<-(dados2$body_mass_g - mean(dados2$body_mass_g, na.rm = T))/sd(dados2$body_mass_g, na.rm=T)
dados2$body_norm2
hist(dados2$body_norm2)
```

Para identificando o tipo de variável, podemos usar algumas funções:

```{r 02- identificacao}
is.numeric(dados2$bill_length_mm)
is.numeric(dados2$species)
is.factor(dados2$species)
is.character(dados2$species)
```

Transformando tipos de variáveis

```{r 02- tipos}
dados2$species<-as.factor(dados2$species)
```

Tem outras opções como as.numeric() e as.matrix()

```{r 02- tipos 2}
head(dados3)
dados3<-as.matrix(dados3)
is.matrix(dados3)
```

## Juntar dados (R base)

Podemos usar o R para juntar dados de diferentes arquivos.

Primeiro vamos carregar alguns dados:

```{r 02- juntar}
dados3<-read.xlsx("dados/dados_bioq.xlsx", sheet=1, colNames=T)
dados4<-read.xlsx("dados/dados_bioq.xlsx", sheet=2, colNames=T)
dados5<-read.xlsx("dados/dados_bioq.xlsx", sheet=3, colNames=T)

```

Esses dados tem diferentes informações da mesma amostra:

```{r 02- juntar 2}
head(dados3)
head(dados4)
head(dados5)
```

Juntando os dados3 e dados4:

```{r 02- juntar 3}
dados6<-merge.data.frame(dados3, dados4, by.x = "ID", by.y = "ID")
head(dados6)
```

Em dados6 tem as amostras que estão presentes em dados3 e também em dados4.

Juntando o objeto resultante com dados5:

```{r 02- juntar 4}
dados7<-merge.data.frame(dados6, dados5, by.x = "ID", by.y = "ID")
head(dados7)
```

Mas também podemos manter apenas os dados de um ou outro objeto:

```{r 02- juntar 5}
dados8<-merge.data.frame(dados6, dados5, by.x = "ID", by.y = "ID", all.x = T)
head(dados8)

dados9<-merge.data.frame(dados6, dados5, by.x = "ID", by.y = "ID", all.y = T)
head(dados9)
```

Ou ainda manter todas as amostras dos 2 objetos

```{r 02- juntar 6 }
dados10<-merge.data.frame(dados6, dados5, by.x = "ID", by.y = "ID", all.x = T, all.y = T)
head(dados10)
```

<!--chapter:end:02-carregar.Rmd-->

# O sistema tidyverse

Tidyverse é um conjunto de pacotes para ciência de dados.
Quando instalamos o pacote tidyverse ele faz a instalação de vários pacotes relacionados: *ggplot2, tibble, tidyr, readr, purrr, dplyr*

```{r 03- tidyverse, message=FALSE, warning=FALSE}
library(tidyverse)
```

Carregando os dados:  

```{r 03- dados}
dados<-read.table("dados/iris.txt", head=T, sep = ",")
```

O R possui muitos dados disponíveis. Podemos carregar esses dados com a função **data()**. Esse arquivo iris pode ser carregado dessa maneira.  
  
  
## Manipulação de dados com tidyverse

Tem várias funções para manipular os dados, entre elas:  

- Selecionar casos por seus valores (filter()).  
- Reordenar as linhas (arrange()).  
- Selecionar  variáveis pelo nome (select()).  
- Criar novas variáveis (mutate()).  
- Colapsar valores em um resumo (summarise()).  

## Função filter  

Definimos o objeto e depois a(s) variável(is). Nesse exemplo abaixo, filtramos os casos (linhas) em que **class** é igual a *Iris-setosa* e que **sepal_w** seja maior que 3.1:

```{r 03- filter}
setosa<-filter(dados, class=="Iris-setosa" & sepal_w > 3.1)
head(setosa)
```

## Função arrange  
  
Com a função arrange podemos ordenar os dados, de forma crescente (default) ou descrescente (adicionando desc), por ou mais variáveis.

```{r 03- arrange}
ordenado<-arrange(dados, desc(sepal_l))
ordenado<-arrange(dados, desc(sepal_l), desc(sepal_w))
head(ordenado)
```

## Função select

Com a função select podemos selecionar variáveis (colunas). Podemos especificar uma coluna ou várias colunas.  

```{r 03- select}
head(dados)
dados2<-select(dados, petal_w )
head(dados2)
```

## Função mutate e transmutate

A função mutate cria uma nova coluna. A nova coluna será adicionada ao final do objeto. Com a função transmutate, o objeto terá apenas a(s) nova(s) coluna(s).
No exemplo abaixo, foram criadas 2 novas colunas, indice e indice2. O conteúdo dessas novas colunas será a multiplicação dos valores de outras variáveis.  

```{r 03- mutate}
dados3<-mutate(dados, indice=sepal_l*sepal_w,
               indice2=petal_l*petal_w)
head(dados3)
```


## Funções group_by e summarise

Essas duas funções são muito úteis quando usadas em conjunto. Na função group_by, especificamos o objeto e uma variável categórica.
Em summarise podemos usar uma função como mean, assim teremos a média da variável especificada, separada pela variável categórica usada em group_by:  

```{r 03- group by}
dados4<-group_by(dados, class)

dados4<-summarise(dados4, sepala=mean(sepal_l))
head(dados4)
```

## Funções pull e distinct

Para extrair uma coluna em forma de vetor:
```{r 03- pull}
x<-pull(dados,sepal_l) 
x
```

Remove linhas com valores repetidos:
```{r 03- distinct}
y<-distinct(dados,sepal_l) 
head(y)
```

Se quiser manter todas as colunas:
```{r 03- distinct 2}
y<-distinct(dados,sepal_l,.keep_all = T)
```


## Pipes

Pipes *(%>%)* é uma ferramenta poderosa para expressar claramente uma sequência de várias operações.
Está disponível nos pacotes do sistema tidyverse.  

```{r 03- pipes}
dados5<-dados%>%
  filter(class=="Iris-setosa")%>%
  mutate(indice=sepal_l*sepal_w)%>%
  arrange(indice)

head(dados5)
```

## Pipe nativa do R
A partir da versão 4.1.0 tem uma versão nativa do R de pipes: |>

```{r 03- Pipe nativa, eval=FALSE, include=FALSE}
mtcars |>
   group_by(cyl) |>
   summarise(mpg = mean(mpg))
```
   

## Tibble

Uma tibble é semelhante ao data frame.
Pode converter um data frame em tibble assim:
```{r 03- tibble}
head(dados)
dados<- as_tibble(dados)
head(dados)
```

Uma das principais diferenças entre tibbles e data frames é que tibbles não convertem automaticamente colunas de texto em fatores. Isso significa que você pode ver os dados exatamente como eles estão armazenados, o que pode ser útil para depurar e analisar dados.

Outra diferença entre tibbles e data frames é que tibbles imprimem com mais linhas e colunas do que cabem na tela. Isso torna mais fácil ver todos os dados em um tibble de uma só vez, sem ter que rolar para cima e para baixo.

Por fim, tibbles incluem algumas estatísticas básicas sobre cada coluna, como a média, a mediana e o desvio padrão. Isso pode ser útil para obter uma visão geral rápida dos dados em um tibble.

## Juntar dados

Juntar dados de diferentes planilhas é uma coisa muito útil, muitas vezes temos diversas planilhas com diferentes informações dos mesmos dados. Juntar esses dados é muito fácil, contanto que tenhamos uma coluna de identificação.  
No pacote dplyr temos as seguintes funções:  

- inner_join - Uma junção interna combina pares de observações sempre que suas chaves são iguais
- left_join -  mantém todas as observações em x.
- right_join - mantém todas as observações em y.
- full_join - mantém todas as observações em x e y.


Tem outras funções interessantes, como **recode** e **case_when()**, para saber mais consulte @wickham2023r


<!--chapter:end:03-tidyverse.Rmd-->

# Gráficos 

O R permite fazer qualquer tipo de gráfico, os quais podem ser personalizados e salvos em diversos formatos e resoluções.  
Existem muitos pacotes gráficos no R e nesse capítulo vamos ver alguns deles.  
  
  
## Gráficos com o pacote graphics (R base)


### Introdução aos gráficos do R

Quando instalamos o R, já temos um pacote para gráficos (graphics) e com ele podemos fazer e personalizar os principais tipos de gráficos.  

Vamos começar carregando os dados. Usaremos o arquivo iris e vamos criar um gráfico de dispersão com as variáveis comprimento e largura das sépalas.

```{r 04- dados, message=FALSE, warning=FALSE}

dados<-read.table("dados/iris.txt", head=T, sep = ",")
head(dados)

plot(dados$sepal_l,dados$sepal_w)
```

Podemos usar mais parâmetros, como type.  

- p: Points.  
- l: Lines.  
- b: Both.  
- c: The lines part alone of b  
- o: Both “overplotted”  
- h: Histogram like (or high-density) vertical lines.  
- n: No plotting.  

```{r 04- plot, message=FALSE, warning=FALSE}
x<-c(1:10)
y<-c(3,7,15,8,10,21,19,12,6,10)
plot(x,y,type="l")
plot(x,y,type="b")
```


Podemos mudar o padrão dos pontos com pch
Os valores vão de 0 a 25:
```{r 04- plot 2}
plot(dados$sepal_l,dados$sepal_w, pch=19)
```


### Salvar


Para salvar um gráfico podemos clicar na opção export, na janela Plots do RStudio ou podemos fazer assim: 

```{r 04- salvar, message=FALSE, warning=FALSE}
png(file="figura1.png", units="in", res = 300, width = 5,height = 5)
plot(dados$sepal_l,dados$sepal_w)
dev.off()
```

As opções de units são: px, in, cm ou mm. Também podemos salvar em outros formatos como jpg ou tif.

Para entender as questões de tamanho e resolução de imagem, consulte: https://pixelcalculator.com/en

É possível fazer vários gráficos na mesma janela usando par() e mfrow().  
Para um arranjo 2 por 2:

```{r 04- par}
par(mfrow=c(2,2)) 
plot(dados$sepal_l,dados$sepal_w)
plot(dados$petal_l,dados$petal_w)
plot(dados$sepal_l,dados$petal_w)
plot(dados$sepal_w,dados$petal_l)
```



Para voltar ao normal:
```{r 04- par 2}
par(mfrow=c(1,1))
plot(dados$sepal_l,dados$sepal_w)
```




Personalizando o gráfico

Podemos usar vários parâmetros para dar nome ao gráficos e aos eixos, especificar as cores, etc.
```{r 04- plot 3}
plot(dados$sepal_l,dados$sepal_w,
     xlab="Nome eixo X", ylab="Nome eixo Y",
     main="Título do gráfico",
     xlim=c(3,9),#limites do eixo x
     ylim=c(1,6),#limites do eixo y
     col="darkmagenta",#cor dos pontos
     pch=22,#formato dos pontos
     bg="darkolivegreen",#cor de preenchimento
     tcl=0.4,#tamanho dos traços dos eixos
     las=1,#orientação dos valores nos eixos: 0,1,2,3
     cex=1.5,#tamanho do ponto
     bty="n")#altera as bordas: "o" (default), 
#"l", "7", "c", "u", or "]" .  "n" suppresses the box.
```


O gráfico pode ficar mais informativo:

```{r 04- plot 4}
dados$class<-as.factor(dados$class)
plot(dados$sepal_l,dados$sepal_w, col = dados$class)
```

Colocando legenda das cores:

```{r 04- plot 5}
dados$class<-as.factor(dados$class)
plot(dados$sepal_l,dados$sepal_w, col = dados$class)

legend('topright', col=unique(dados$class), legend=levels(dados$class), pch =1)
```


Se quiser especificar as cores:

```{r 04- plot 6}
plot(dados$sepal_l,dados$sepal_w, col = c('red', 'blue', 'green')[as.numeric(dados$class)])
```

Brincando com as cores:

```{r 04- plot 7}
val <- dados$sepal_l + dados$sepal_w
maxnovo<-1
minnovo<-0

valcol<-((val-min(val))/(max(val) - min(val)))*(maxnovo - minnovo) + minnovo

plot(dados$sepal_l,dados$sepal_w, pch = 15, col = gray(valcol))
```



Podemos explorar os dados:
```{r 04- pairs}
pairs(dados)
```



Acrescentando cor por espécie:
```{r 04- pairs 2}
pairs(dados,col = dados$class)
```




### Histogramas

Para fazer um histograma usamos a função hist.
```{r 04- hist}
hist(dados$sepal_l)
```



Também podemos personalizar o histograma:
```{r 04- hist 2}
hist(dados$sepal_l,
     main="Folha",
     xlab="comprimento sépala",
     ylab="Frequência",
     col=c("gold4","darkseagreen4"),
     border="black",
     adj=0, #alinhamento do texto
     col.axis="forestgreen")#cor do texto nos eixos
```



### Boxplot

Outro tipo de gráfico bastante usado é o boxplot
```{r 04- boxplot}
boxplot(dados$sepal_l ~ dados$class, 
        main="Sépalas", names= c("Iris-setosa","Iris-versicolor","Iris-virginica"),xlab="espécies",
        ylab="comprimento")
```

Podemos personalizar o boxplot:
```{r 04- boxplot 2}
boxplot(dados$sepal_l ~ dados$class, 
        main="Sépalas", names= c("Iris-setosa","Iris-versicolor","Iris-virginica"),xlab="espécies",
        ylab="comprimento",
        notch=T,
        col=c("brown1","khaki1", "blue"))
```


As cores podem ser especificadas pelo nome da cor ou pelo código hex.
Os nomes e os códigos podem ser encontrados em vários sites como:

http://www.sthda.com/english/wiki/colors-in-r
http://sape.inf.usi.ch/quick-reference/ggplot2/colour


### Barplot

Também temos o gráfico de barras. Embora tenha semelhamças com o histograma, os histogramas são  barras conectadas umas às outras, visualizando a distribuição de uma variável quantitativa contínua e os gráficos de barras usam retângulos de tamanho proporcional para visualizar algum tipo de dados categóricos.

Podemos criar uma tabela de frequência com a função table e usar o resultado para criar um gráfico de barras:

```{r 04- barplot}
x<-table(dados$class) 
barplot(x, col = c("brown1","khaki1", "blue"))
```


## O pacote ggplot2

O pacote ggplot2 é um dos principais pacotes gráficos do R.

Os elementos de um gráfico (dados, sistema de coordenadas, rótulos, anotações, entre outros) são as camadas e a construção de um gráfico se dá pela sobreposição dessas camadas.


### Gráficos de pontos (dispersão)

```{r 04- geom_point, message=FALSE, warning=FALSE}
library(ggplot2) 
ggplot(dados) +
  geom_point(aes(sepal_l, sepal_w))
```

- A primeira camada é dada pela função ggplot() e recebe a nossos dados;
- A segunda camada é dada pela função geom_point(), especificando a forma geométrica utilizada no mapeamento das observações (pontos);
- As camadas são unidas com um +;
- O mapeamento na função geom_point() recebe a função aes(), responsável por descrever como as variáveis serão mapeadas nos aspectos visuais dos pontos (a forma geométrica escolhida);
- Neste caso, os aspectos visuais mapeados são a posição do ponto no eixo x e a posição do ponto no eixo y;

Podemos usar pipes:
```{r 04- pipes}
library(dplyr)
dados%>% ggplot() +
  geom_point(aes(x = sepal_l, y = sepal_w))
# obs: não precisamos colocar x e y
```

         

Podemos criar um objeto ggplot e depois adicionar camadas:

```{r 04- camadas, message=FALSE, warning=FALSE}
p <- ggplot(dados)

p + geom_point(aes(sepal_l, sepal_w,color= class))+
  labs(title="Iris", x = "Comprimento das sépalas", y = "Largura das sépalas", color = "Espécies")
```



Também podemos alterar o tamanho:


```{r 04- geom_point 2, message=FALSE, warning=FALSE}
p + geom_point(aes(sepal_l, sepal_w, size= class))
  
```


Podemos adicionar mais camadas:

```{r 04- facet_wrap}
p + geom_point(aes(sepal_l, sepal_w, color= class))+
  facet_wrap(~class)
```


### Salvar

Para salvar usamos a função ggsave, que vai salvar o último gráfico gerado:

```{r 04- ggsave}
ggsave(
  "figura.jpg",
  plot = last_plot(),
  dpi = 300,
)
```



Vamos carregar outra planilha de dados:

```{r 04- dados 3}
library(openxlsx)
dados2<-read.xlsx("dados/Data_Cortex_Nuclear.xlsx", sheet = 1, colNames = T)
head(dados2)
```
Esses dados podem ser baixados do seguinte endereço:  
https://archive.ics.uci.edu/dataset/342/mice+protein+expression  
[@misc_mice_protein_expression_342]  

Podemos selecionar algumas colunas e criar um objeto ggplot:

```{r 04- select}
p <- dados2 %>% 
  select(DYRK1A_N:pAKT_N,Genotype:class)%>%
  ggplot(aes(DYRK1A_N, ITSN1_N, color = Genotype))
```

E criar um gráfico de dispersão:

```{r 04- dispersao, message=FALSE, warning=FALSE}
p + geom_point(size = 0.7)
```

Podemos mudar as escalas dos eixos x e y. Por exemplo, vamos usar uma escala logarítmica (log na base 10):

```{r 04- scale_x, message=FALSE, warning=FALSE}
p + geom_point(size = 1) +
  scale_x_log10() +
  scale_y_log10()
```



### Histogramas

Criando um objeto ggplot:
```{r 04- geom_histogram}
p <- dados2 %>% 
    ggplot(aes(x = DYRK1A_N))
```

Histograma básico:

```{r 04- geom_histogram 2, message=FALSE, warning=FALSE}
p + geom_histogram()
```

Personalizando a cor de preenchimento, cor da linha e legendas:

```{r 04- geom_histogram 3, message=FALSE, warning=FALSE}
p + geom_histogram(binwidth = 0.1, fill = "blue", col = "black") +
  xlab("expressão") +
  ggtitle("Histograma")
```


### Density plot

Um gráfico de densidade é uma representação da distribuição de uma variável numérica. É uma versão suavizada do histograma e é usado no mesmo conceito.

```{r 04- geom_density, message=FALSE, warning=FALSE}
p + geom_density()
```
   
Podemos usar cores:
 
```{r 04- geom_density 2, message=FALSE, warning=FALSE}
p + geom_density(fill = "blue")
```

Transparência  

```{r 04- geom_density 3, message=FALSE, warning=FALSE}
ggplot(dados2, aes(EGR1_N, fill = class, colour = class)) +
  geom_density(alpha = 0.2, na.rm = TRUE)
```


### Boxplot

O boxplot é um gráfico onde a parte central contém os valores que estão entre o primeiro quartil e o terceiro quartil. As hastes inferiores e superiores se estendem, respectivamente, do primeiro quartil até o menor valor, limite inferior, e do terceiro quartil até o maior valor.

```{r 04- geom_boxplot}
p <- dados2 %>% 
  ggplot(aes(y = ADARB1_N , group=class, color=class))

p + geom_boxplot()
```

### Gráfico Q-Q
O gráfico Q-Q é um gráfico de probabilidades, usado para comparar duas distribuições de probabilidade, traçando seus quantis uns contra os outros. 


QQ-plot básico no ggplot2:

```{r 04- geom_qq, message=FALSE, warning=FALSE}
p <- dados2 %>% 
  select(DYRK1A_N:pAKT_N,Genotype:class)%>%
  filter(Genotype =="Ts65Dn")%>%
  ggplot(aes(sample = DYRK1A_N))

p + geom_qq()
```

Podemos fazer um QQ-plot contra uma distribuição normal com a mesma média e desvio padrão:
```{r 04- geom_qq 2, message=FALSE, warning=FALSE}
params <- dados2 %>% 
  select(DYRK1A_N:pAKT_N,Genotype:class)%>%
  filter(Genotype =="Ts65Dn")%>%
  summarize(mean = mean(DYRK1A_N, na.rm = T), sd = sd(DYRK1A_N, na.rm=T))
p + geom_qq(dparams = params) +
  geom_abline()
```

### Figura com vários gráficos

Para juntar vários gráficos do ggplot2 em uma imagem usamos o pacote gridExtra

Vamos primeiro criar os gráficos e armazer em p1, p2, p3:

```{r 04- gridextra}
p <- dados2 %>% 
  select(DYRK1A_N:pAKT_N,Genotype:class)%>%
  ggplot(aes(x = DYRK1A_N))

p1 <- p + geom_histogram(binwidth = 0.1, fill = "blue", col = "black")
p2 <- p + geom_histogram(binwidth = 0.2, fill = "red", col = "black")
p3 <- p + geom_histogram(binwidth = 0.3, fill = "green", col = "black")
```

Então usamos o pacote gridExtra para compor a imagem. Nesse exemplo, vamos dispor as imagens em uma linha e três colunas:

```{r 04- gridextra 2, message=FALSE, warning=FALSE}
library(gridExtra)
grid.arrange(p1, p2, p3, ncol = 3)
```

### Ajustes de Posição
position = “identity” irá colocar cada objeto na posição exata em que ele cairia no contexto do gráfico
```{r 04- position}
p + geom_bar(aes(class, fill=Genotype),
             position="identity")
```



position = “dodge” coloca objetos sobrepostos um ao lado do outro. Isto torna mais fácil a comparação de valores individuais

```{r 04- position 2}
p + geom_bar(aes(Genotype, fill=class),
           position="dodge")
```



position = “fill” irá empilhar os elementos um sobre o outro, mas normalizando a altura. Isso é muito útil para comparar proporções entre os grupos  

```{r 04- position 3}
p + geom_bar(aes(Genotype, fill=class),
             position="fill")
```

### Geom Smooth

```{r 04- geom_smooth, message=FALSE, warning=FALSE}
ggplot(dados2, aes(SNCA_N,EGR1_N)) +
  geom_point() +
  geom_smooth(method = lm, size = 1)
```



Para saber mais:  
@wickham2023r @irizarry2019introduction]




## Outros pacotes gráficos

Vamos carregar os dados e ativar os pacotes:
```{r 04- dados 4, message=FALSE, warning=FALSE}
library(ggplot2)
library(RColorBrewer)
library(openxlsx)
library(dplyr)
dados<-read.xlsx("dados/pinguim.xlsx", sheet = 1, colNames = T)
head(dados)


```

### Usando as cores

Primeiro vamos fazer um gráfico, sem especificar quais cores usar:

```{r 04- cores, message=FALSE, warning=FALSE}
p <- dados %>% 
  ggplot(aes(y = bill_length_mm, group=species, color=species))

p + geom_boxplot()
```



No ggplot2, é possível armazenar a paleta de cores em uma variável e usá-la posteriormente.

Por exemplo:

```{r 04- cores 2}
cbPalette <- c("#999999", "#E69F00", "#56B4E9", "#009E73", "#F0E442", "#0072B2", "#D55E00", "#CC79A7")
```

Então podemos usar essas cores no gráfico:


```{r 04- cores 3, message=FALSE, warning=FALSE}
p <- dados %>% 
  ggplot(aes(y = bill_length_mm, group=species, fill=species))

p + geom_boxplot()+
  scale_fill_manual(values=cbPalette)
```


Para o preenchimento adicionamos:

scale_fill_manual(values=cbPalette)

Para cor da linha ou pontos adicionamos:

scale_colour_manual(values=cbPalette)

Também podemos usar outras escalas de cores, como as retiradas do pacote RColorBrewer


```{r 04- cores 4, message=FALSE, warning=FALSE}
p + geom_boxplot()+
  scale_fill_brewer(palette="Set1")


p + geom_boxplot()+
  scale_fill_brewer(palette="Oranges")
```


Podem consultar as opções em: https://r-graph-gallery.com/38-rcolorbrewers-palettes.html




### Análise gráfica exploratória

```{r 04- ggally, message=FALSE, warning=FALSE}
library(GGally)
dados2<-select(dados, species, bill_length_mm:body_mass_g)
```



 Para isso usaremos o pacote GGally, que é uma extensão para o ggplot2.
 
 
Vamos usar a função ggpairs e selecionar uma variável categórica para color:

```{r 04- ggally 2, message=FALSE, warning=FALSE}
ggpairs(dados2, aes(color = species))
```

### GGPLOT2: mais parâmetros  

Vamos usar outro geom, o geom_segment:

```{r 04- geom_segment, warning=FALSE}
ggplot(dados, aes(x=bill_length_mm , y=bill_depth_mm )) +
  geom_segment( aes(x=bill_length_mm , xend=bill_length_mm , y=10, yend=bill_depth_mm), color="grey") +
  geom_point(color="orange", size=4) +
  theme_light() +
  theme(
    panel.grid.major.x = element_blank(),
    panel.border = element_blank(),
    axis.ticks.x = element_blank()
  ) +
  xlab("") +
  ylab("Value of Y")
```

### Diagrama de Venn

Vamos criar uma lista com dados aleatórios  

```{r 04- venn}
set.seed(654925)            

list_venn <- list(A = sort(sample(1:100, 20)),
                  B = sort(sample(1:100, 20)),
                  C = sort(sample(1:100, 20)),
                  D = sort(sample(1:100, 20)))
head(list_venn)  
```

Carregar o pacote ggvenn e fazer o diagrama com  A e C:  

```{r 04- venn 2, message=FALSE, warning=FALSE}
library(ggvenn)
ggvenn(list_venn, c("A", "C"))   
```


Fazer o diagrama com  A, C e D:  

```{r 04- venn 3, message=FALSE, warning=FALSE}
ggvenn(list_venn, c("A", "C", "D"))
```

Com todos os dados:  

```{r 04- venn 4}
ggvenn(list_venn) 
```

### Diagramas

Muitas vezes precisamos fazer um diagrama, ou fluxograma, para mostrar as etapas da pesquisa e podemos fazer isso usando o pacote DiagrammeR

```{r 04- diagrama, message=FALSE, warning=FALSE}
library(DiagrammeR)


figura1<-DiagrammeR::grViz("
digraph a_nice_graph {
  node [fontname = Helvetica, color = green]
  a [label = 'Ratos', color =blue, fontname=Impact]
  b [label = 'caso, n = 20']
  c [label = 'controle, n = 20']
  d [label = 'medicamento']
  e [label = 'salina']
  f [label = '30 days']
  g [label = 'córtex', color= blue]
  h [label = 'hipocampo' , color= blue]
  i [label = 'fígado', color =blue]
  j [label = 'atividade enzimática', color =red,fontname=Impact]
  # edge definitions with the node IDs
  a -> {b c}
  b -> d
  c -> e
  {d e} -> f
  f -> {g h i}
  {g h i} -> j
}
")
figura1
```

Para salvar esse diagrama é preciso carregar mais 2 pacotes: rsvg e DiagrammeRsvg


```{r 04- diagrama 2, message=FALSE, warning=FALSE}
library(rsvg)
library(DiagrammeRsvg)
figura1 = DiagrammeRsvg::export_svg(figura1)
figura1 = charToRaw(figura1) # flatten
rsvg_png(figura1, file = "figura1b.png", width = 5961, height = 7016)
```

### Outra opção é o pacote ggflowchart  

Para usar esse pacote tem um tutorial no endereço abaixo:  
(https://nrennie.rbind.io/blog/introducing-ggflowchart/)  

```{r 04- diagrama 3, eval=FALSE, include=FALSE}
remotes::install_github("nrennie/ggflowchart")
```

  
```{r 04- diagrama 4, message=FALSE, warning=FALSE}

library(ggflowchart)
data <- tibble::tibble(from = c("A", "A", "A", "B", "C", "F"),
                       to = c("B", "C", "D", "E", "F", "G"))

ggflowchart(data)
```
  
Podemos usar os seguintes parâmetros:  

- fill = "white". A cor de preenchimento.
- colour = "black". A cor da caixa de texto.
- text_colour = "black". A cor do texto.
- text_size = 3.88. O tamanho do texto.
- arrow_colour = "black". A cor das flechas.
- arrow_size = 0.3. O tamanho das flechas.
- family = "sans". A fonte do texto.
- x_nudge = 0.35. A largura da caixa de texto.
- y_nudge = 0.25. A altura da caica de texto.
- horizontal = FALSE. A direção do fluxograma.  
  
Alguns exemplos:  
```{r 04- diagrama 5}
ggflowchart(data,
            colour = "blue",
            text_colour = "red",
            arrow_colour = "green",
            family = "serif",
            x_nudge = 0.4,
            y_nudge = 0.2,
            arrow_size = 0.3)
```

Com fluxograma na horizontal:  
```{r 04- diagrama 6}
ggflowchart(data,
            colour = "blue",
            text_colour = "black",
            arrow_colour = "orange",
            family = "serif",
            x_nudge = 0.4,
            y_nudge = 0.2,
            arrow_size = 0.3,
            horizontal = T)
```

Utilizando tipos diferentes:  

```{r 04- diagrama 7}
node_data <- tibble::tibble(
  name = c("A", "B", "C", "D", "E", "F", "G"),
  type = c("Type 1", "Type 1", "Type 1", "Type 1", 
           "Type 2", "Type 2", "Type 2")
)
ggflowchart(data, node_data, fill = type)

```

  
  
### Datas e séries temporais

Vamos plotar uma variável (peso) ao longo do tempo.
Primeiro vamos carregar os dados:  

```{r 04- series temporais}
dados3<-read.xlsx("dados/peso.xlsx", sheet=1,colNames = T)
head(dados3)
```
Nesse arquivo temos a variável grupo (caso e controle), uma variável tempo (t1 a t6) e a variável peso. São 2 grupos de animais, que foram pesados em 6 momentos.  
Agora ativaremos uma função para organizar os dados para poder fazer o gráfico:

```{r 04- series temporais 2}
data_summary <- function(data, varname, groupnames){
  require(plyr)
  summary_func <- function(x, col){
    c(mean = mean(x[[col]], na.rm=TRUE),
      sd = sd(x[[col]], na.rm=TRUE))
  }
  data_sum<-ddply(data, groupnames, .fun=summary_func,
                  varname)
  data_sum <- rename(data_sum, c("mean" = varname))
  return(data_sum)
}
```

Agora que a função data_summary está ativa, vamos preparar os dados:  

```{r 04- series temporais 3, message=FALSE, warning=FALSE}
df <- data_summary(dados3, varname="peso", 
                   groupnames=c("grupo", "tempo"))

df
```

E finalmente o gráfico:
```{r 04- series temporais 4}
p<- ggplot(df, aes(x=tempo, y=peso, group=grupo, color=grupo)) + 
  geom_line() +
  geom_point() +
  geom_errorbar(aes(ymin=peso-sd, ymax=peso+sd), width=.2,
                position=position_dodge(0.05))
p
```


Personalizando o gráfico:
```{r 04- series temporais 5}
p+labs(title="Weight variation along 30 days", x="Time", y = "Weight")+
  theme_classic() +
  scale_color_manual(values=c('#999999','#E69F00'))

```


Além da definição das cores, que já vimos, aqui usamos também o theme_classic()  
Esses temas controlam outros aspectos visuais do gráfico.  
Tem vários temas:

theme_grey()  
theme_gray()  
theme_bw()  
theme_linedraw()  
theme_light()  
theme_dark()  
theme_minimal()  
theme_classic()  
theme_void()  
theme_test()  

### Time series - Dados de casos de COVID no Paraná

Os dados podem ser baixados de:
https://www.saude.pr.gov.br/Pagina/Coronavirus-COVID-19
Como exemplo, vou usar os dados de março de 2022, porque quanto mais recente, maior o arquivo e demora mais para carregar e processar os dados.  

Carregar os dados:

```{r 04- series temporais 6, warning=FALSE}
dados<-read.csv("dados/informe_epidemiologico_16_03_2022_geral.csv", header = T, sep = ";")
library(dplyr)
head(dados)
dados<-select(dados, SEXO:MUN_RESIDENCIA,DATA_DIAGNOSTICO,DATA_INICIO_SINTOMAS,DATA_OBITO)
```

Os dados tem colunas com data, no entanto, para o R entender que são datas devemos usar o pacote lubridate.
Devemos olhar como está o formato da data. Nesse caso estão no formato ano, mês, dia, então usamos função ymd:

```{r 04- series temporais 7, warning=FALSE}
library(lubridate)

dados$DATA_INICIO_SINTOMAS <-ymd(dados$DATA_INICIO_SINTOMAS)
dados$DATA_DIAGNOSTICO <-ymd(dados$DATA_DIAGNOSTICO)
dados$DATA_OBITO <-ymd(dados$DATA_OBITO)
```


Podemos plotar o número de casos por data de diagnóstico:  

```{r 04- series temporais 8, message=FALSE, warning=FALSE}
library(ggplot2)
p <- dados %>%
  ggplot(aes(DATA_DIAGNOSTICO))
p + geom_bar(fill = "dodgerblue")
```


Podemos ver a idade dos casos positivos:

```{r 04- series temporais 9}
dados %>%
  filter(IDADE_ORIGINAL>=0)%>%
  ggplot(mapping = aes(IDADE_ORIGINAL )) +
  geom_bar(fill="goldenrod1", col="black")
```

Ou a idade dos casos de óbito:  

```{r 04- series temporais 10}
dados %>%
  filter(!is.na(DATA_OBITO))%>%
  ggplot(mapping = aes(x =IDADE_ORIGINAL )) +
  geom_bar(fill="firebrick1", col="black")
```


Podemos separa por sexo:

```{r 04- series temporais 11}
dados %>%
  ggplot(aes(DATA_DIAGNOSTICO, color = SEXO, fill=SEXO)) +
  geom_density(alpha=0.2 )
```


Filtros

Podemos usar filtros, por exemplo, por data:

```{r 04- series temporais 12}
p <- dados %>%
  filter(DATA_DIAGNOSTICO>as.Date("2022-02-15"))%>%
  ggplot(aes(DATA_DIAGNOSTICO))
p + geom_bar(fill = "dodgerblue")
```


Filtrando por município:

```{r 04- series temporais 13}
p <- dados %>%
  filter(MUN_RESIDENCIA=="PONTA GROSSA")%>%
  ggplot(aes(x = DATA_DIAGNOSTICO))
p + geom_bar(fill = "blue")
```


Além desses gráficos todos apresentados aqui, existem muitos outros, os quais vocês podem procurar conforme a necessidade.  
  
Mais detalhes podem ser obtidos em @wickham2023r


<!--chapter:end:04-graficos.Rmd-->

# Estatística

## Estatística descritiva

O R permite fazer qualquer teste estatístico.
No R base já temos o pacote stats que possibilita fazer vários testes estatísticos. Além disso temos muitos outros pacotes estatísticos.

Primeiro vamos fazer uma estatística descritiva, obtendo os valores de média, mediana, desvio padrão, máximo, mínimo.

Os dados que vamos usar estão no pacote palmerpenguins.

```{r 05- dados, message=FALSE, warning=FALSE}
library(openxlsx)
dados<-read.xlsx("dados/pinguim.xlsx", sheet = 1, colNames = T)
head(dados)

# caracterização
mean(dados$bill_length_mm , na.rm=T) # média
median(dados$bill_length_mm , na.rm=T) # mediana
sd(dados$bill_length_mm , na.rm=T) # desvio padrão
max(dados$bill_length_mm , na.rm=T) # máximo
min(dados$bill_length_mm , na.rm=T) # mínimo

summary(dados$bill_length_mm )
```
  
## Testes estatísticos

Tipos de testes estatísticos  

Existem testes paramétricos e não paramétricos.
Primeiro passo: verificar como é a distribuição dos nossos dados.
Podemos  fazer um gráfico assim:

```{r 05- grafico}
m<-mean(dados$bill_length_mm ,na.rm=TRUE)
std<-sd(dados$bill_length_mm ,na.rm=TRUE)
hist(dados$bill_length_mm , prob=TRUE)
curve(dnorm(x, mean=m, sd=std), 
      col="darkblue", lwd=2, add=TRUE, yaxt="n")
```

Ou podemos fazer um gráfico qq plot:

```{r 05- qqplot, message=FALSE, warning=FALSE}
library(ggplot2)
library(dplyr)
p <- dados %>% 
    ggplot(aes(sample= bill_length_mm))

params <- dados %>% 
  summarize(mean = mean(bill_length_mm, na.rm = T), sd = sd(bill_length_mm, na.rm=T))
p + geom_qq(dparams = params)+
  geom_abline()
```

### Normalidade  

Através dos gráficos podemos ter uma ideia da distribuição dos dados, mas isso não é um teste estatístico. Para testar a normalidade
podemos usar o teste Kolmogorov-Smirnov com correção de Lilliefors,
para isso precisamos instalar ativar o pacote nortest:  

```{r 05- nortest, message=FALSE, warning=FALSE}
library(nortest)


lillie.test(dados$bill_length_mm )
```

Esses dados são de diferentes espécies, então devemos testar a normalidade em cada grupo:

```{r 05- nortest 2, message=FALSE, warning=FALSE}
library(dplyr)

adelie<-filter(dados, species=="Adelie")
gentoo<-filter(dados, species=="Gentoo")
chinstrap<-filter(dados, species=="Chinstrap")


lillie.test(adelie$bill_length_mm)
lillie.test(gentoo$bill_length_mm)
lillie.test(chinstrap$bill_length_mm)
```

Também podemos usar o teste de Shapiro-Wilk para testar a normalidade:

```{r 05- shapiro}
shapiro.test(adelie$bill_length_mm)
shapiro.test(gentoo$bill_length_mm)
shapiro.test(chinstrap$bill_length_mm)
```

### Assimetria e curtose  

Em estatística, assimetria (skewness) e curtose (kurtosis) são duas maneiras de medir a forma de uma distribuição.

A assimetria é uma medida da assimetria de uma distribuição. Este valor pode ser positivo ou negativo.

Um valor de zero indica que não há assimetria na distribuição, o que significa que a distribuição é perfeitamente simétrica.

Curtose mede a concentração ou dispersão dos valores de um conjunto de valores em relação às medidas de tendência central.

A curtose de uma distribuição normal é 3.
Se uma dada distribuição tem uma curtose menor que 3, ela tende a produzir menos outliers e menos extremos do que a distribuição normal.
Se uma dada distribuição tem uma curtose maior que 3, ela tende a produzir mais outliers do que a distribuição normal.


```{r 05- moments, message=FALSE, warning=FALSE}
library(moments)
skewness(adelie$bill_length_mm, na.rm = T)
# zero não tem skewnwss
# para valor de p:
agostino.test(adelie$bill_length_mm)

# para kurtosis, o valor sem kurtosis é 3
kurtosis(adelie$bill_length_mm, na.rm = T)

# para valor de p:
anscombe.test(adelie$bill_length_mm)
```



Se os dados tem distribuição normal podemos comparar as médias usando o teste t, mas precisamos saber se as variâncias são iguais:

```{r 05- var.test}
var.test(adelie$bill_length_mm, gentoo$bill_length_mm)
```

### Teste t
```{r 05- teste-t}
t.test(adelie$bill_length_mm, gentoo$bill_length_mm, var.equal=T)
```

Se o teste de variância não foi significativo, usamos var.equal=T, caso contrário, usamos var.equal=F

Para dados não paramétricos temos o teste Mann-Whitney (para duas amostras) ou Wilcoxon (para uma amostra pareada: paired = T):

```{r 05- manwhitney}
wilcox.test(adelie$bill_length_mm, gentoo$bill_length_mm)
```



### Teste qui-quadrado

chisq.test(x, correct = TRUE,
            simulate.p.value = FALSE, B = 2000)

correct: one half is subtracted from all |O - E| differences
simulate.p.value: a logical indicating whether to compute p-values by Monte Carlo simulation
B:  an integer specifying the number of replicates used  in the Monte Carlo test

Exemplos:  

```{r 05- quiquadrado}
x<-rbind(c(163,147),c(109,125)) # criar tabela com os dados

x
chisq.test(x,correct=F)

x<-rbind(c(163,147,130),c(109,125,125))
x
chisq.test(x,correct=F)

chisq.test(x,simulate.p.value = T, B = 10000)
```


### Correlação

cor(x, use=, method= ) 

use:	como tratar dados faltantes. 
       Options are all.obs (sem NA), 
       complete.obs (listwise deletion), 
       pairwise.complete.obs (pairwise deletion)
method	tipo de  correlação. 
       Options are pearson, spearman or kendall.

Pearson (entre duas variáveis contínuas), que é um 
      teste paramétrico.
Spearman (ou rho) ? uma correlação de "rankings" ou 
     "postos", # e por isso é um teste não-paramétrico
Kendall (ou tau) vai na mesma linha não-paramétrica 
     da correlação de Spearman
     
```{r 05- correlacao}
cor(adelie$bill_length_mm , adelie$body_mass_g, use="pairwise.complete.obs", 
    method = "pearson")
```
     
```{r 05- correlacao 2, message=FALSE, warning=FALSE}
# plot the data
library(PerformanceAnalytics)
mydata<-select(adelie, bill_length_mm :body_mass_g)
chart.Correlation(mydata,  method = "pearson")
```




### Regressão

A regressão linear é uma análise que avalia se uma ou mais variáveis preditoras explicam a variável dependente. A regressão tem cinco pressupostos principais:

Relação linear
Normalidade
Nenhuma ou pouca multicolinearidade
Sem auto-correlação
Homocedasticidade (Homogeneidade de Variância)

Na regressão linear requer pelo menos 20 casos por variável independente na análise.

Vamos transformar as variáveis species e island em uma variável numérica, utilizando mutate e ifelse:

```{r 05- regressao}
dados<-mutate(dados, especie= ifelse(grepl("Adelie",species), 0, 
                                     ifelse(grepl("Gentoo", species),1,2)))

dados<-mutate(dados, ilha= ifelse(grepl("Torgersen",island), 0, 
                                     ifelse(grepl("Biscoe", island),1,2)))

head(dados)
```

O grepl é uma função que procura correspondências de uma string ou vetor de string. O método grepl() pega um padrão e retorna TRUE se uma string contiver o padrão, caso contrário, FALSE.

No R temos duas funções para fazer a regressão:  
lm, Usada para ajustar modelos lineares
lm(formula, data, …)
fórmula: (y ~ x1 + x2)  
  
glm, Usada para ajustar modelos lineares generalizados.
glm(formula, family=gaussian, data, …)
family: A família estatística a ser usada para ajustar o modelo. O padrão é gaussiano, mas outras opções incluem binomial, gama e poisson, entre outros. 


Fazendo a regressão com a função glm, como variável dependente body_mass_g e como variáveis independentes especie e ilha:

```{r 05- regressao 2}
regressao<-glm(body_mass_g ~  especie + ilha, data=dados, family=gaussian)

summary(regressao)
```

### ANOVA

Análise de variância (ANOVA)

A análise da variância (ou ANOVA, de "ANalysis Of VAriance") é uma poderosa técnica estatística desenvolvida por R.A. Fisher. Ela consiste em um procedimento que decompõe, em vários componentes identificáveis, a variação total entre os valores obtidos no experimento. Cada componente atribui a variação a uma causa ou fonte de variação diferente: o número de causas de variação ou "fatores" depende do delineamento da investigação.

Um dos modelos mais simples de ANOVA é o que analisa os dados de um delineamento completamente casualizado ou ANOVA a um critério de classificação (One way ANOVA). Neste modelo, a variação global é subdividida em duas frações. A primeira é a variação entre as médias dos vários grupos, quando comparadas com a média geral de todos os indivíduos do experimento e representa o efeito dos diferentes tratamentos. A outra é a variação observada entre as unidades experimentais de um mesmo grupo ou tratamento, com relação à média desse grupo: tratam-se das diferenças individuais, ou aleatórias, nas respostas. 

Resumidamente:

Variação total = Variação entre tratamentos + Variação dentro dos tratamentos.

A variação entre grupos experimentais ou tratamentos é estimada pela variância entre tratamentos ou simplesmente Variância Entre. A variação dentro do mesmo tratamento é estimada pela média das variâncias de cada grupo: é por isso chamada variancia média dentro dos grupos ou Variância Dentro. Como ela representa também a fração da variabilidade que não é explicada pelo efeito dos tratamentos, é também chamada Variância Residual ou, ainda, Variância do Erro Experimental.

O teste de comparação entre os efeitos dos tratamentos baseia-se na pressuposição de que os k tratamentos A,B,... podem originar médias diferentes, mas a entre os indivíduos (o) é igual em todas as populações que estão sendo comparadas. Em outras palavras, deseja-se testar a hipótese de igualdade estre médias.

Antes de fazer a ANOVA, vamos fazer o teste de Bartlett para verificar a variância:

```{r 05- anova, message=FALSE, warning=FALSE}
library(car) 

bartlett.test(bill_length_mm ~species,data=dados)

```

Como não foi significativo, vamos fazer a ANOVA com a função aov:

```{r 05- anova 2}
res_anova<-aov(bill_length_mm~species,data=dados)
summary(res_anova)
```

O resultado foi significativo, mas com a ANOVA sabemos que tem diferença, mas não sabemos entre quais grupos,então podemos usar o teste de Duncan:

```{r 05- anova 3, message=FALSE, warning=FALSE}
library(agricolae)
duncan.test(res_anova,"species",console = T)

```

Para vizualizar essas diferenças podemos fazer gráficos:

```{r 05- anova 4, message=FALSE, warning=FALSE}
library("ggpubr")
ggline(dados, x = "species", y = "bill_length_mm", 
       add = c("mean_se", "jitter"), 
       ylab = "bill_length_mm", xlab = "espécies",color = "species")
       

ggboxplot(dados, x = "species", y = "bill_length_mm", 
          color = "species", palette = c("#00AFBB", "#E7B800", "#FC4E07"),
          ylab = "bill_length_mm", xlab = "species")
```

Para dados não paramétricos, podemos usar o teste de Kruskal-Wallis

```{r 05- kruskal}
kruskal.test(bill_length_mm ~ species, data = dados)
```

Para esse caso, podemos o usar o teste de Dunn para identificar as diferenças:

```{r 05- kruskal 2, message=FALSE, warning=FALSE}
library(FSA)

dunnTest(bill_length_mm ~ species, data = dados,
              method="bh") 
```



## Visualização de resultados estatísticos

Vamos usar alguns pacotes que vão ajudar na análise de dados e também gerar um relatório com tabelas e gráficos em um documento html ou doc. 



O pacote DataExplorer permite fazer diversas análises. Podemos ter uma visão inicial dos dados com a função introduce

```{r 05- dataexplorer}
library(DataExplorer)
introduce(dados)
```

Também podemos ver na forma de gráficos:  

```{r 05- dataexplorer 2}
plot_intro(dados)
```

Os dados categóricos podem ser plotados:  

```{r 05- dataexplorer 3, message=FALSE, warning=FALSE}
plot_bar(dados, by="species")

dados%>%
  select(species, bill_length_mm:body_mass_g)%>%
  plot_boxplot(by="species")

```

Outro pacote muito útil é o ggstatsplot, com o qual podemos unir gráficos e análises estatísticas. Por exemplo, para dados categóricos:  


```{r 05- ggstatsplot}
library(ggstatsplot)

ggbarstats(data = dados, x = species , y= island, label = "both")

```

Ou para dados numéricos:  

```{r 05- ggstatsplot 2}
ggbetweenstats(data= dados, x=species, y=bill_length_mm, type = "p")

```
  
  Onde em type temos as seguintes opções: p (parametric), np (non parametric), r (robust), bf (bayes).  
  
  
  

O pacote dlookr descreve cada variável e o pacote flextable permite criar tabelas com os resultados. Podemos fazer diversas análises usando a função describe.  

```{r 05- dlookr, message=FALSE, warning=FALSE}
library(dlookr)
library(flextable)

dlookr::describe(dados)%>%
  flextable()
# obs, usar dlookr:: porque describe tem em outros 2 pacotes

```
  
Também podemos usar a função diagnose_numeric:  

```{r 05- dlookr 2}
dados%>%
  diagnose_numeric()%>%
  flextable()
```

  
O pacote SmartEDA também faz um resumo descritivo das variáveis numéricas  

```{r 05- smarteda}
library(SmartEDA)
ExpNumStat(dados, by="A", round = 2)%>%
  flextable()
```

Em by temos as opções A: All, G: by group e GA: by group e Overall:  

```{r 05- smarteda 2}
ExpNumStat(dados, by="G", gp="species", round = 2)%>%
  flextable()

ExpNumStat(dados, by="GA", gp="species", round = 2)%>%
  flextable()
```

Podemos ter os dados de saída de diversas análises estatísticas organizados com o pacote report.  


```{r 05- report}
library(report)
dados2<-na.omit(dados)
flextable(report_table(wilcox.test(dados2$bill_length_mm~dados2$sex))) 
```

Também podemos personalizar as tabelas geradas pelo pacote flextable.  

```{r 05- flextable}
flextable(report_table(wilcox.test(dados2$bill_length_mm~dados2$sex)))%>%
  colformat_double(digits = 2)%>%
  style(i = 1, j = 4, pr_t = fp_text_default(bold = T))
```


Para saber mais consulte @irizarry2019introduction e @gohel2023flextable  

<!--chapter:end:05-estatistica.Rmd-->

# Funções e loops

## Funções

Uma função recebe alguns dados de entrada, faz algumas operações e devolve os dados de saída.

```{r 06- funcoes}
funcao<-function(x, y)  #criando uma função
{                       #inicio
  result<- x^2+y^2      #calculando
  return(result)        #valor a ser retornado
}                       #fim
```

                      
Usando a função:  

```{r 06- funcoes 2}
funcao(10,6)
```

Quando ativamos um pacote, estamos ativando as funções daquele pacote.
Podemos ver o conteúdo das funções digitando e executando o nome da função.

```{r 06- funcoes 3}
funcao
```

Outro exemplo, podemos transformar em uma função aquele script que faz um histograma e sobrepõe a curva da distribuição normal:

```{r 06- funcoes 4}
curva<-function(x){
  m<-mean(x,na.rm=TRUE)
  std<-sd(x,na.rm=TRUE)
  hist(x, prob=TRUE)
  curve(dnorm(x, mean=m, sd=std), 
        col="darkblue", lwd=2, add=TRUE, yaxt="n")
}
```

Usando a função:

```{r 06- funcoes 5}
library(openxlsx)
dados<-read.xlsx("dados/pinguim.xlsx", sheet = 1, colNames = T)

curva(dados$bill_length_mm)

curva(dados$bill_depth_mm)

curva(dados$flipper_length_mm)

curva(dados$body_mass_g)
```


Porque escrever funções?
  
Uma função te força a escrever tudo em termos gerais. 
As funções são criadas para tarefas que serão repetidas várias vezes. Em vez de copiar e colar o código várias vezes fazendo as alterações necessárias, usar funções é uma maneira muito mais razoável de resolver o problema e, uma vez criada e debbugada, é muito mais prático de usar.

Um desafio é que o return só aceita um único objeto, ou seja, funções no R só retornam uma única coisa. 

Quando precisa retornar mais de uma coisa, uma opção é o list(), recebe qualquer coisa. 

Outra coisa que pode ser feita é quebrar uma função grande em funções menores. O R permite que uma função chame outra, o que facilita em muito o processo de criação de funções complicadas.

## Loops

São processos interativos para realizar uma sequências de comandos até uma condição predeterminada.

### for

Uma comando para isso é o for() 
Para esse comando usamos um contador.
Exemplo:

```{r 06- loops}
i<-1
for(i in 1:5) print(i)
```

Podemos vários comandos. Nesse os comandos são colocados entre{}

```{r 06- loops 2}
i<-1
for(i in 1:5){
  print(i)
  print(i^2)
  print("teste")
}
```

### while

Outro comando é o while

```{r 06- loops 3}
j<-1
while(j<6){
  print(j)
  print("teste")
  j<-j+1
}
```

## if e else

Com os comandos if e else se uma condição for atendida é executada uma ação.

Por exemplo:

```{r 06- loops 4}
x<-2

if(x==1) print("sim") else print("não")

```


Podemos usar o if e else dentro de um loop:

```{r 06- loops 5}
i<-1
for(i in 1:10){
  if(i<6) print("sim") else print("não")
}

```


Agora vamos usar um loop para fazer o teste de chi-quadrado e torná-lo mais funcional.
Nesse exemplo temos que montar um arquivo de entrada com as seguintes características:
- o arquivo de entrada deve ter a primeira coluna identificando  a comparação
- os valores das duas colunas seguintes são os valores do  primeiro grupo em seguida os valores do outro grupo
- exemplo: grupo 1 tem 200 ind. com alelo 1 e 300 com alelo 2  e o grupo 2 tem 250 com alelo 1 350 com alelo 2, então: comp1 200 300 250 350


Vamos rodar um exemplo para isso vamos carregar o arquivo, transformar em matriz:

```{r 06- loops 6}
dados4<-read.xlsx("dados/quiquadrado.xlsx", sheet = 1, colNames = F,rowNames = T)
dados5<-as.matrix(dados4)
dados5
```


Vamos criar um objeto (nomes) com os nomes das linhas.
Agora vamos criar o loop, usando o comando for. O número de repetições do loop vai ser definido pelo número de elementos em nomes. Vamos armazenar os resultados em um arquivo txt:


```{r 06- loops 7}
nomes<-row.names(dados5)
nomes
i<-1 
for (i in nomes) {
  a<-dados5[i,1] # linha i, coluna 1
  b<-dados5[i,2] # linha i, coluna 2
  c<-dados5[i,3] # linha i, coluna 3
  d<-dados5[i,4] # linha i, coluna 4
  quadrado<-rbind(c(a,c),c(b,d))
  res_qui<-chisq.test(quadrado,correct=F)
  write(i,file="resultados/resultado_quiquadrado.txt",  append = T)
  capture.output(res_qui, file="resultados/resultado_quiquadrado.txt",  append = T)
}
```



## Funções apply, lapply, sapply, tapply, mapply

A família Apply representa um conjunto de funções básicas do R que permite realizar operações sobre os dados contidos nas várias estruturas disponíveis  (vetor, data frame, listas). 

A utilização destas funções permitem automatizar a aplicação das operações desejadas, permitindo assim ganhos de velocidade durante procedimentos que necessitam ser repetidos sobre todos os dados.

A função apply é para matriz

```{r 06- apply}
library(dplyr)
dados3<-dados%>%
  select(bill_length_mm:body_mass_g)
dados3<-as.matrix(dados3)

apply(dados3, 2, mean, na.rm=T) # 2 indica colunas, 1 indica linhas
```

A função lapply é para lista:

```{r 06- apply 2}
x<-list(a = 1:4, b = rnorm(10), c = rnorm(20,1), d = rnorm(100,5))
x
lapply(x, mean)
```

A função sapply é parecida com lapply, mas retorna vetor ou matriz:

```{r 06- apply 3}
sapply(x, mean) 
```

A função tapply é utilizada para aplicar um procedimento a diferentes partes dos dados dentro de um array, matriz ou data frame. 
Ela difere das demais funções vistas até aqui por exigir a existência de uma variável categórica, a qual servirá para agrupar os dados aos diferentes níveis. 

```{r 06- apply 4}
tapply(dados$bill_length_mm, dados$sex, mean, na.rm=T)
```


A função mapply é uma versão multivariada da função lapply. As funções lapply e sapply atuam somente sobre os elementos de uma única lista. 
No caso da função mapply a função é aplicada sobre o primeiro elemento de cada um dos argumentos, em seguida ao segundo elemento, seguindo ao terceiro, e assim por diante. 

```{r 06- apply 5}
mapply(sum, dados$bill_length_mm, dados$bill_depth_mm)
```



<!--chapter:end:06-funcoes.Rmd-->

# Genética

## Genética de populações


No estudo de genética de populações, alguns cálculos básicos são as frequências alélicas e genotípicas, verificar se está em equilíbrio de Hardy-Weinberg e também verificar o desequilíbrio de ligação.

Esses cálculos podem ser feitos com o pacote genetics.

Vamos carregar alguns dados de exemplo:

```{r 07-genetics}
dados<-read.table("dados/genotipagem.txt", head=T)
head(dados)
```


Vamos carregar o pacote genetics:

```{r 07-genetics 2, message=FALSE, warning=FALSE}
library(genetics)
snp<-"rs1800977"  #substituir  pelo gene/SNP de interesse
```

Agora vamos usar a função genotype, onde em sep informamos o separador de alelos nos dados.

```{r 07-genetics 3}
genotipos1<-na.omit(genotype(dados$rs1800977, sep="/")) 
genotipos1
```

Podemos ver os resultados de frequências usando summary:

```{r 07-genetics 4}
resultado1<-summary(genotipos1)
resultado1
```

Para verificar o equilíbrio de Hardy-Weinberg usamos a função HWE.chisq:

```{r 07-genetics 5}
eqhw1<-HWE.chisq(genotipos1)
eqhw1
```

Podemos salvar os resultados em um arquivo txt, onde vamos usar o objeto snp para especificar de qual SNP são os resultados:

```{r 07-genetics 6}
write("Frequencias alelicas e genotipicas.", file="res.genes.txt",append=T)
write(snp, file="res.genes.txt", append=T)
capture.output(resultado1, file="res.genes.txt",append = T)
capture.output(eqhw1, file="res.genes.txt", append = T)
```

Também podemos gerar figuras com as frequências:

```{r 07-genetics 7}
plot(genotipos1, type="allele", what="percentage")

plot(genotipos1, type="genotype", what="percentage")
```

Para salvar as figuras com as frequências, onde filename=paste(snp,"alelo.jpg", sep="": serve para criar o nome do arquivo juntando o conteúdo de snp + alelo.jpg, sem espaço, definido por sep sem nada:

```{r 07-genetics 8}
jpeg(filename=paste(snp,"alelo.jpg", sep=""))
plot(genotipos1, type="allele", what="percentage")
dev.off()

jpeg(filename=paste(snp,"genotipo.jpg", sep=""))
plot(genotipos1, type="genotype", what="percentage")
dev.off()
```


Desequilíbrio de ligação

Também podemos calcular o desequilíbrio de ligação entre 2 SNPs com a função LD, mas primeiro criamos os objetos com os dados dos SNPs com a função genotype:

```{r 07-genetics 9}
rs1800977<-na.omit(genotype(dados$rs1800977, sep="/"))
rs2230806<-na.omit(genotype(dados$rs2230806, sep="/"))
ld<-LD(rs1800977,rs2230806)
ld
```

## Genotipagem com genetics e loop  
  
  
Vamos juntar os conhecimentos de loops, que já aprendemos, para genotipar vários SNPs e criar um arquivo de saída mais elaborado:

No arquivo que estamos usando, tem uma coluna grupo (caso e controle). Usaremos essa coluna para criar 2 objetos:

```{r 07-genetics 10, message=FALSE, warning=FALSE}
library(dplyr)
caso<-filter(dados, grupo==1)   
controle<-filter(dados, grupo==2) 
```

Precisamos detalhar o que tem em resultados1:

```{r 07-genetics 11}
names(resultado1)
```

Em allele.fre e genotype.freq temos uma matriz com os resultados:

```{r 07-genetics 12}
resultado1$allele.freq
resultado1$genotype.freq
```

Com base nisso, precisamos definir quais dados queremos salvar e criar uma tabela com as variáveis. 
Aqui criamos o objeto tabela.saida, que é um data.frame e especificamos as colunas:

```{r 07-genetics 13}
tabela.saida<-data.frame(grupo=as.character(NA),SNP=as.character(NA),genot1=as.character(NA), N1=NA, F1=NA,genot2=as.character(NA), N2=NA, F2=NA,genot3=as.character(NA),N3=NA,F3=NA,alelo1=as.character(NA),N4=NA,F4=NA,alelo2=as.character(NA),N5=NA,F5=NA,hw=NA,qui_genot=NA,qui_alel=NA,stringsAsFactors = F)
```

Agora vamos criar o loop, usando for, para fazer a genotipagem e equilíbrio de HW, de cada SNP, no grupo caso e no grupo controle, depois compare por qui-quadrado as frequências alélicas e genotípica entre casos e controles.

```{r 07-genetics 14, warning=FALSE}
nomes<-colnames(dados) #nomes dos SNPs
i<-2 #número da coluna inicial para genotipar
snp<-7 # número da coluna final para genotipar
j<-1

for (i in i:snp) {
  nome_snp<-nomes[i]
  genotipos1<-na.omit(genotype(caso[,i], sep="/"))#genotipagem
  resultado1<-summary(genotipos1)#sumariza resultados
  eqhw1<-HWE.chisq(genotipos1)#equilíbrio de HW
  nome_genot<-rownames(resultado1$genotype.freq)
  nome_alelos<-rownames(resultado1$allele.freq)
  
  
  tabela.saida[j,]<-data.frame(grupo=as.character("caso"),SNP=as.character(nome_snp),genot1=as.character(nome_genot[1]), N1=resultado1$genotype.freq[1,1], F1=resultado1$genotype.freq[1,2],genot2=as.character(nome_genot[2]), N2=resultado1$genotype.freq[2,1],F2=resultado1$genotype.freq[2,2], genot3=as.character(nome_genot[3]),N3=resultado1$genotype.freq[3,1],F3=resultado1$genotype.freq[3,2],alelo1=as.character(nome_alelos[1]),N4=resultado1$allele.freq[1,1],F4=resultado1$allele.freq[1,2],alelo2=as.character(nome_alelos[2]),N5=resultado1$allele.freq[2,1],F5=resultado1$allele.freq[2,2],hw=eqhw1$p.value,qui_genot=NA,qui_alel=NA,stringsAsFactors = F)
  j<-j+1
  
  genotipos2<-na.omit(genotype(controle[,i], sep="/"))#genotipagem
  resultado2<-summary(genotipos2)#sumariza resultados
  eqhw2<-HWE.chisq(genotipos2)#equilíbrio de HW
  
  #qui-quadrado alelo
  a<-resultado1$allele.freq[1,1]
  b<-resultado1$allele.freq[2,1]
  c<-resultado2$allele.freq[1,1]
  d<-resultado2$allele.freq[2,1]
  quadrado<-rbind(c(a,c),c(b,d))
  quadrado
  res_qui<-chisq.test(quadrado,correct=F)
  
  #qui-quadrado genotipo
  g<-resultado1$genotype.freq[1,1]
  h<-resultado1$genotype.freq[2,1]
  l<-resultado1$genotype.freq[3,1]
  k<-resultado2$genotype.freq[1,1]
  m<-resultado2$genotype.freq[2,1]
  o<-resultado2$genotype.freq[3,1]
  quadrado2<-rbind(c(g,k),c(h,m),c(l,o))
  res_qui2<-chisq.test(quadrado2,correct=F)
  
  tabela.saida[j,]<-data.frame(grupo=as.character("controle"),SNP=as.character(nome_snp),genot1=as.character(nome_genot[1]), N1=resultado2$genotype.freq[1,1], F1=resultado2$genotype.freq[1,2],genot2=as.character(nome_genot[2]), N2=resultado2$genotype.freq[2,1],F2=resultado2$genotype.freq[2,2], genot3=as.character(nome_genot[3]),N3=resultado2$genotype.freq[3,1],F3=resultado2$genotype.freq[3,2],alelo1=as.character(nome_alelos[1]),N4=resultado2$allele.freq[1,1],F4=resultado2$allele.freq[1,2],alelo2=as.character(nome_alelos[2]),N5=resultado2$allele.freq[2,1],F5=resultado2$allele.freq[2,2],hw=eqhw2$p.value,qui_genot=res_qui2$p.value,qui_alel=res_qui$p.value,stringsAsFactors = F)
  
  
  
  i<-(i+1)
  j<-j+1
}
```

Verificando os resultados:

```{r 07-genetics 15}
library(flextable)
flextable(tabela.saida)
```


Para terminar vamos salvar os resultados em um arquivo xlsx:

```{r 07-genetics 16}
library(openxlsx)
write.xlsx(tabela.saida, file="genotipagem.xlsx")
```


## Heredogramas

Também podemos gerar heredogramas usando o R, para isso usamos o pacote
kinship2 e carregar o arquivo de exemplo:

```{r 07- heredogramas, message=FALSE, warning=FALSE}
library(kinship2)
familia<-read.xlsx("dados/familia.xlsx", sheet=1, colNames = T)
head(familia)
```
Nessa planilha temos uma coluna com a identificação única de de cada indivíduo (ids), duas colunas identificando os pais (dad e mom), uma coluna para o sexo, uma coluna com a informação se o indivíduo está vivo ou não (dead) e uma última coluna (caract) que indica se o indivíduo tem a característica de interesse.  

Usando a função pedigree:

```{r 07- heredogramas 2}
family <- pedigree(id=familia$ids, dadid=familia$dad, momid=familia$mom, affected=familia$caract, sex=familia$sex, status=familia$dead)
```

E plotando o heredograma:

```{r 07- heredogramas 3}
plot.pedigree(family,cex = 0.8, col = c("red","blue","green","red","blue","green","red","blue","green","black"))
```


## Análises filogenéticas

O pacote APE (Analysis of Phylogenetics and Evolution) permite fazer vários tipos de análises (http://ape-package.ird.fr/).

Podemos pegar sequências de DNA diretamente do Genbank:

```{r 07- ape, message=FALSE, warning=FALSE}
library(ape)

id_seq<-c("NM_001081850.1","NM_000055.3","NM_009738.3")
seq_bche<-read.GenBank(id_seq)
seq_bche
```

Também é possível ler um arquivo fasta:

```{r 07- ape 2}
pon<-read.FASTA("dados/PON123.fas")
pon
```


E com a função nj podemos fazer uma árvore pelo método neighbor-joining de Saitou and Nei (1987).

```{r 07- ape 3}
pon.trw<-nj(dist.dna(pon))
plot(pon.trw)
```




<!--chapter:end:07-genetica.Rmd-->

# Network

Em várias áreas temos dados complexos de interações entre diferentes grupos de elementos que estão sendo analisados e para esses casos, um gráfico de rede ajuda a visualizar essas interações, que podem ser espécies, genes ou pessoas.  

Conceitos básicos:
Vértices (Vertices) e arestas (edges)

Vértices: é um ponto em que duas ou mais curvas, retas ou arestas se encontram.
Arestas:  segmento de reta que liga dois vértices.  

Os objetos para fazer uma rede é uma matriz de adjacências, que é uma matriz quadrada, onde os nomes das linha e colunas são os vértices e os valores dentro da matriz indicam uma conexão (1) dos vértices ou não (0). No entanto, podemos criar um objeto para rede a partir de um dataframe, como veremos depois.

## Pacote Igraph


Um dos principais pacotes para criar gráficos de redes é o igraph, cujo manual pode ser consultado em https://igraph.org/r/

Existem muitas funções para criar diferentes estruturas de gráficos no Igraph.

Conceitos básicos:
Vértices (Vertices) e arestas (edges)

Vértices: é um ponto em que duas ou mais curvas, retas ou arestas se encontram
Arestas:  segmento de reta que liga dois vértices

Exemplo:

```{r 08- igraph, message=FALSE, warning=FALSE}
library(igraph)
g<-graph.full(n=10, directed = FALSE, loops = F)
plot(g)
```


Gráfico completo: cada par de vértices tem uma aresta conectando-os, o argumento LOOPS = FALSE significa que as arestas próprias não são adicionadas.

 Gráficos com a lista de arestas (edges) fornecida:
 
```{r 08- igraph 2}
edges <- c(1,2, 3,2, 2,4)
g<-graph(edges, n=max(edges), directed=TRUE)
plot(g)
```
 
Podemos montar um arquivo com os vértices e arestas

```{r 08- igraph 3}
library(openxlsx)
arestas<-read.xlsx("dados/miRNA2.xlsx", sheet=1,colNames = T)
vertices<-read.xlsx("dados/miRNA2.xlsx", sheet=2,colNames = T)
head(arestas)
head(vertices)
```

Vamos criar o objet net com a função graph_from_data:

```{r 08- igraph 4}
net <- graph_from_data_frame(arestas, directed=T) 
net
```

E gerar o gráfico:

```{r 08- igraph 5}
plot(net, edge.arrow.size=.2,vertex.label=vertices$nome, vertex.label.color="blue", vertex.label.dist=3, vertex.size=5)
```


Podemos ainda mudar configurações:

```{r 08- igraph 6}
l <- layout_with_kk(net)
l <- norm_coords(l, ymin=-1, ymax=1, xmin=-1, xmax=1)

plot(net, rescale=F, layout=l*1.2, edge.arrow.size=.2,vertex.label=vertices$nome, vertex.label.color=vertices$tipo, vertex.label.dist=3, vertex.size=5, vertex.color=vertices$tipo)
```




<!--chapter:end:08-network.Rmd-->

# Bioconductor



O projeto Bioconductor desenvolve, apoia e dissemina software de código aberto gratuito que facilite a análise rigorosa e reprodutível de dados de ensaios biológicos atuais e emergentes. 
  
Conta com mais de 2000 pacotes.
A versão atual (3.17) requer a versão 4.3.0 do R.
   
Para instalar pacotes do Bioconductor precisa do pacote BiocManager:

if (!require("BiocManager", quietly = TRUE))
    install.packages("BiocManager")
BiocManager::install(version = "3.16") 
  
Depois os pacotes podem ser instalados assim:
  
BiocManager::install(c("GenomicFeatures", "AnnotationDbi"))
  
Para procurar pacotes:

```{r 09- bioconductor}
BiocManager::available("expression")
```

O site é: https://bioconductor.org/


## Pacote msa


Vamos instalar o pacote msa (Multiple Sequence Alignment):
An R Package for Multiple Sequence Alignment
Enrico Bonatesta, Christoph Kainrath, and Ulrich Bodenhofer
Institute of Bioinformatics, Johannes Kepler University Linz, Austria

BiocManager::install("msa")

Vamos carregar algumas sequências usando o pacote ape:

```{r 09- msa}
library(ape)
id_seq<-c("NM_022942.1","NM_009738.3","NM_001313861.2")
seq_bche<-read.GenBank(id_seq)
seq_bche
```

Temos que salvar em formato fasta, para depois usar esse arquivo no msa.  
O formato FASTA é um formato baseado em texto para representar tanto sequencias de nucleotideos quanto sequencias de aminoácidos. O formato também permite sequências de nomes e comentários precedendo as sequências.  
  

```{r 09- msa 2}
write.FASTA(seq_bche, file = "seq_bche.fasta")
```

  
Agora vamos fazer o alinhamento usando o pacote msa, onde informamos o tipo de sequência em type (pode ser dna,rna ou protein), em method escolhemos o método de alinhamento, sendo as opções: "ClustalW", "ClustalOmega" e "Muscle". Iremos utilizar o  ClustalW.
  

```{r 09- msa 3, message=FALSE, warning=FALSE}
library(msa)

alin<-msa("seq_bche.fasta", type = "dna", method = "ClustalW")

alin
```

Para ver o alinhamento vamos usar outro pacote, o ggmsa:
instalar o pacote ggmsa
BiocManager::install("ggmsa")

Precisamos fazer algumas transformações no objeto alin antes de usar no ggmsa:
  

```{r 09- msa 4, message=FALSE, warning=FALSE}
library(ggmsa)
# converter para o formato do ape
ali_bche<-msaConvert(alin, type="ape::DNAbin")

# salvar no formato fasta
write.FASTA(ali_bche, file = "ali_bche.fas")

# ler o arquivo fasta
ali_bche2<-read.FASTA("ali_bche.fas")
```

Agora vamos gerar a figura com o alinhamento:

```{r 09- msa 5}
ggmsa(ali_bche2, 1000, 1030, char_width = 0.5, seq_name = F) 
```

Acrescentando uma camada:

```{r 09- msa 6}
ggmsa(ali_bche2, 1000, 1020, char_width = 0.5, seq_name = T) + geom_seqlogo(color = "Chemistry_NT")
```

Acrescentando a sequência consenso:

```{r 09- msa 7}

ggmsa(ali_bche2, 1000, 1020, char_width = 0.8, seq_name = T) + geom_seqlogo(color = "Chemistry_NT") + geom_msaBar()
```


Esquema de cores
ggmsa predefine vários esquemas de cores para renderização. Podemos usar available_msa() para listar os esquemas de cores disponíveis.  
Observe que aminoácidos (proteína) e nucleotídeos (DNA/RNA) têm nomes diferentes.   

DNA:  
Chemistry_NT Shapely_NT Taylor_NT Zappo_NT  

Proteínas:  

Clustal Chemistry_AA Shapely_AA Zappo_AA Taylor_AA LETTER CN6 Hydrophobicity  



Abaixo estão as camadas de anotação suportadas pelo ggmsa:  

Annotation modules	Type	Description
geom_seqlogo()	geometric layer	automatically generated sequence logos for a MSA
geom_GC()	      annotation module	shows GC content with bubble chart
geom_seed()	    annotation module	highlights seed region on miRNA sequences
geom_msaBar()	  annotation module	shows sequences conservation by a bar chart
geom_helix()	  annotation module	depicts RNA secondary structure as arc diagrams(need extra data)

  
  
## Pacote multiMiR

Para insatalar:
BiocManager::install("multiMiR")


Os microRNAs (miRNAs) regulam a expressão promovendo a degradação ou reprimindo a tradução de transcritos alvo. Os sítios alvo de miRNA foram catalogados em bancos de dados com base em validação experimental e previsão computacional usando uma variedade de algoritmos.

O pacote R multiMiR  (http://multimir.org), é uma coleção abrangente de interações miRNA-alvo previstas e validadas e suas associações com doenças e medicamentos. O multiMiR inclui vários novos recursos não disponíveis em pacotes R existentes.

As informações de cada banco de dados externo são armazenadas em uma tabela no banco de dados multiMiR. Para ver uma lista das tabelas, podemos usar a função multimir_dbTables().

```{r 09- multiMiR}
library(multiMiR)
multimir_dbTables()
```

Podemos ver os detalhes de cada banco:

```{r 09- multiMiR 2}
multimir_dbInfo()
```

Entre os 14 bancos de dados externos, oito contêm interações miRNA-alvo previstas, três têm interações miRNA-alvo validadas experimentalmente e os três restantes contêm associações miRNA-droga/doença. 

Para verificar essas categorias e bancos de dados de dentro do R, temos um conjunto de quatro funções auxiliares:

```{r 09- multiMiR 3}
predicted_tables()
validated_tables()
diseasedrug_tables()
reverse_table_lookup("targetscan")
```

Para ver quantos registros existem nesses 14 bancos de dados externos, nos referimos à função multimir_dbCount.

```{r 09- multiMiR 4}
multimir_dbCount()
```

A função list_multimir() listar todos os miRNAs únicos, genes alvo, drogas e doenças no banco de dados multiMiR. Uma opção para limitar o número de registros retornados foi adicionada para ajudar nos testes e na exploração.

```{r 09- multiMiR 5}
miRNAs<- list_multimir("mirna", limit = 10)
genes<- list_multimir("gene", limit = 10)
drugs<- list_multimir("drug", limit = 10)
diseases<- list_multimir("disease", limit = 10)

miRNAs
genes
drugs
diseases
```

get_multimir() é a principal função no pacote para recuperar interações miRNA-alvo previstas e validadas e suas associações de doenças e medicamentos do banco de dados multiMiR.

Podemos pesquisar por miRNA:

```{r 09- multiMiR 6}
example1 <- get_multimir(mirna = 'hsa-miR-125a-5p', summary = TRUE)

# Check which types of associations were returned
table(example1@data$type)
# Detailed information of the validated miRNA-target interaction
head(example1@data)
```

Podemos pesquisar por medicamento:

```{r 09- multiMiR 7}
example2 <- get_multimir(disease.drug = 'cisplatin', table = 'disease.drug')
head(example2@data)
```

Podemos pesquisar por gene:

```{r 09- multiMiR 8}
example3 <- get_multimir(org     = "hsa",
                         target  = "BCHE",
                         table   = "predicted",
                         summary = TRUE,
                         predicted.cutoff      = 35,
                         predicted.cutoff.type = "p",
                         predicted.site        = "all")

table(example3@data$type)
head(example3@data)
head(example3@summary)
```

Você pode ter uma lista de genes envolvidos em um processo biológico comum. É interessante verificar se alguns, ou todos, desses genes são direcionados pelo(s) mesmo(s) miRNA(s).

```{r 09- multiMiR 9}
example4 <- get_multimir(org     = 'hsa',
                         target  = c('AKT2', 'CERS6', 'S1PR3', 'SULF2'),
                         table   = 'predicted',
                         summary = TRUE,
                         predicted.cutoff.type = 'n',
                         predicted.cutoff      = 500000)

example4.counts <- addmargins(table(example4@summary[, 2:3]))
example4.counts <- example4.counts[-nrow(example4.counts), ]
example4.counts <- example4.counts[order(example4.counts[, 5], decreasing = TRUE), ]
head(example4.counts)
```


<!--chapter:end:09-bioconductor.Rmd-->

# Dados não estruturados

Muitos dados estão apresentados de forma não estruturada, como por exemplo textos, imagens, vídeos e sons.
No entanto, também podemos analisar esse tipo de dados. Por exemplo, um texto pode ser utilizado em um processo de mineração de dados.  
Nesse capítulo veremos com trabalhar com textos, imagens e sons no R.  

## Texto

Você pode usar qualquer texto, salve como um arquivo txt.  
Vamos carregar um arquivo de texto. Para isso usaremos o pacote tm:  

```{r 10- tm, message=FALSE, warning=FALSE}
library(tm)
library(dplyr)
texto<-Corpus(DirSource(getwd(),pattern = "texto.txt"))

```

Mas o texto carregado não está em um formato que possa ser analisado, então usamos a função VectorSource que  interpreta cada elemento do vetor x como um documento.

```{r 10- tm 2}
docs <- Corpus(VectorSource(texto))
```

Mas um texto tem muitos elementos que não são tão relevantes para uma análise, como pontuação, espaços, stop words e números.
Podemos resolver isso com as seguintes funções:

```{r 10- tm 3, message=FALSE, warning=FALSE}
docs <- docs %>%
  tm_map(removeNumbers) %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
```


Agora transformamos em uma matriz:

```{r 10- tm 4, message=FALSE, warning=FALSE}
dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm)
head(matrix)
```

Podemos criar um objeto com as palavras e organizamos as palavras por frequência:

```{r 10- tm 5, message=FALSE, warning=FALSE}
words <- sort(rowSums(matrix),decreasing=TRUE) 
df <- data.frame(word = names(words),freq=words)
head(df)
```


Para procurar os termos mais frequentes usamos a função findFreqTerms, por exemplo, procurar os termos que ocorrem pelo menos 10 vezes:

```{r 10- tm 6}
inspect(dtm)
findFreqTerms(dtm, 10) 
```

Uma das coisas que é possível fazer com esse objeto é uma nuvemn de palavras, para isso vamos usar o pacote wordcloud2:

```{r 10- wordcloud2}
library(wordcloud2)
wordcloud2(data=df, size=1.6, color='random-dark')
```


### Análise de sentimentos

A Análise de Sentimentos é o estudo computacional de opiniões, sentimentos e emoções expressas em um texto.  
Na educação, ela é empregada como método para a obtenção do “feedback” dos alunos ou avaliação de professores.  
  
Os professores as vezes têm que lidar com grandes quantidades de mídia textual, o que é trabalhoso e demanda tempo. Nesse cenário, a utilização de ferramentas computacionais que os auxiliem na tarefa de analisar textos é muito atrativa.  
A ideia é que se possa identificar a tendência geral de uma turma em relação ao tema em discussão, sem a necessidade de ler todos os textos, que podem ser volumosos.  


Como exemplo, vamos o mesmo texto, mas agora usaremos o pacote pdftools para ler um arquivo pdf.

```{r 10- sentimentos, message=FALSE, warning=FALSE}
library(pdftools)

texto2<-pdf_text("texto.pdf")
```

E agora usaremos o pacote syuzhet para fazer a análise de sentimentos.  

  
```{r 10- sentimentos 2, message=FALSE, warning=FALSE}
library(syuzhet)
library(RColorBrewer)

sentimentos <- get_nrc_sentiment(texto2, lang="english", lowercase = T)
```
  
E plotamos o resultado em um gráfico:  

```{r 10- sentimentos 3, message=FALSE, warning=FALSE}
barplot(
  colSums(prop.table(sentimentos[, 1:8])),
  space = 0.2,
  horiz = FALSE,
  las = 1,
  cex.names = 0.7,
  col = brewer.pal(n = 8, name = "Set3"),
  xlab=NULL, ylab = NULL)
```

Também podemos resumir em sentimentos positivos e negativos:  
  
```{r 10- sentimentos 4, message=FALSE, warning=FALSE}
barplot(
  colSums(prop.table(sentimentos[, 9:10])),
  space = 0.2,
  horiz = FALSE,
  las = 1,
  cex.names = 0.7,
  col = c("tomato","skyblue3"),
  xlab=NULL, ylab = NULL)
```
  

## Imagens

As imagens são outro tipo de dado não estruturado e também podem ser carregadas e editadas. Como  exemplo veremos o pacote magick.

```{r 10- imagens, message=FALSE, warning=FALSE}
library(magick)

foto<-image_read('dados/foto.jpg')
foto
```

Também podemos salvar em diferentes formatos:  

```{r 10- imagens 2}
image_write(foto, path = "dados/foto.png", format = "png")
```


### Edição de imagens

Podemos cortar a imagem:  
500px por350px começando na esquerda em +1550px:   

```{r 10- imagens 3}
image_crop(foto, "500x350+1550") 
```

Para redimensionar proporcionalmente à largura:

```{r 10- imagens 4}
image_scale(foto, "500")
```

Para redimensionar proporcionalmente à altura:

```{r 10- imagens 5}
image_scale(foto, "x200")
```
 
Adicionar uma borda:

```{r 10- imagens 6}
image_border(foto, "red", "20x10")
```

Vamos redimensionar a imagem para fazer outras alterações

```{r 10- imagens 7}
foto2<-image_scale(foto, "400")
foto2
```

Rotações de imagem:

```{r 10- imagens 8}
image_rotate(foto2, 45)
image_flip(foto2)
image_flop(foto2)
```

Brilho, saturação e matiz:

```{r 10- imagens 9}
image_modulate(foto2, brightness = 80, saturation = 120, hue = 90)
```


Pintar a mesa de laranja:

```{r 10- imagens 10}
image_fill(foto2, "orange", point = "+100+200", fuzz = 20)
```


Outros efeitos:

```{r 10- imagens 11}
image_blur(foto2, 10, 5)
image_charcoal(foto2)
image_oilpaint(foto2)
image_negate(foto2)
```


Adicionando texto:

```{r 10- imagens 12}
image_annotate(foto2, "Laboratório", size = 70, gravity = "southwest", color = "green")
```


Personalizando o texto;

```{r 10- imagens 13}
image_annotate(foto2, "UFPR", size = 30, color = "red", boxcolor = "pink", degrees = -45, location = "+150+100",font = 'Times')
```


Usando pipes  
Cada uma das funções de transformação de imagem retorna uma cópia modificada da imagem original. Não afeta a imagem original.

```{r 10- imagens 14}
foto2 %>%
  image_rotate(270) %>%
  image_background("blue", flatten = TRUE) %>%
  image_border("red", "10x10") %>%
  image_annotate("Lab", color = "blue", size = 50)
```


Vamos carregar outra imagem:

```{r 10- imagens 15}
logo<-image_read('dados/R.PNG')
logo
```

E colocar as duas imagens em um vetor:

```{r 10- imagens 16}
img <- c(foto2, logo)
```

Um mosaico imprime imagens umas sobre as outras, expandindo a tela de saída de forma que tudo se encaixe:

```{r 10- imagens 17}
image_mosaic(img)
```



O achatamento combina as camadas em uma única imagem que tem o tamanho da primeira imagem.
O nivelamento e o mosaico permitem especificar operadores compostos alternativos:

```{r 10- imagens 18}
image_flatten(img, 'Add')

image_flatten(img, 'Modulate')

image_flatten(img, 'Minus')
```



Combinando imagens  
Anexar significa simplesmente colocar os quadros um ao lado do outro:

```{r 10- imagens 19}
image_append(image_scale(img, "x200"))

image_append(image_scale(img, "100"), stack = TRUE)
```

A composição permite combinar duas imagens em uma posição específica:

```{r 10- imagens 20}
logo2<-image_scale(image_rotate(image_background(logo, "none"), 300), "x200")

image_composite(image_scale(foto2, "x400"), logo2, offset = "+180+100")
```



Animação  
Em vez de tratar os elementos vetoriais como camadas, também podemos transformá-los em quadros em uma animação.

```{r 10- imagens 21}
image_animate(image_scale(img, "300x300"), fps = 1, dispose = "previous")
```

  


Morphing cria uma sequência de n imagens que transformam gradualmente uma imagem em outra. Faz animações

```{r 10- imagens 22}
newlogo <- image_scale(image_read("https://jeroen.github.io/images/Rlogo.png"))
oldlogo <- image_scale(image_read("https://jeroen.github.io/images/Rlogo-old.png"))
image_resize(c(oldlogo, newlogo), '200x150!') %>%
  image_background('white') %>%
  image_morph() %>%
  image_animate(optimize = TRUE) 
```




## Áudio

Assim como as imagens, também podemos trabalhar com arquivos de áudio. Para isso, utilizaremos o pacote tuneR. 
Vamos usar um arquivo de áudio em mp3.

```{r 10- audio, message=FALSE, warning=FALSE}
library(tuneR)
bird <- readMP3("dados/bird.mp3")
bird
plot(bird)
```
Usando:
play(bird)
será acionado um player de áudio para tocar o áudio.

Pegaremos apenas um canal para extrair algumas informações do áudio.

```{r 10- audio 2}
wobjm <- mono(bird, "left")
WspecObject <- periodogram(wobjm, normalize = TRUE, width = 1024, overlap = 512)
```


 Vejamos o primeiro periodograma:
```{r 10- audio 3}
plot(WspecObject, xlim = c(0, 3000), which = 1)
```
 
Ou o espectrograma:
```{r 10- audio 4}
image(WspecObject, ylim = c(0, 500))
```

Calculando a frequência fundamental
```{r 10- audio 5}
ff <- FF(WspecObject)
print(ff)
```


Derivar nota de FF dado diapasão A=440
```{r 10- audio 6}
notes <- noteFromFF(ff, 440)
```


Suavizar as notas:
```{r 10- audio 7, message=FALSE, warning=FALSE}
library(pastecs)
snotes <- smoother(notes)
```


O resultado deve ser 0 para o A do diapasão  e -12 (12 meios-tons abaixo) para A

```{r 10- audio 8}
print(snotes) 
```


Plotar a melodia e energia do som:
```{r 10- audio 9}
melodyplot(WspecObject, snotes)
```



Aplique alguma quantização (em 8 partes) e um gráfico, 4 partes por barra:  

```{r 10- audio 10}
qnotes <- quantize(snotes, WspecObject@energy, parts = 8)
quantplot(qnotes, expected = rep(c(0, -12), each = 4), bars = 2)
```

E preparando o objeto para o LilyPond.
LilyPond é um programa de gravação de música, dedicado a produzir partituras de alta qualidade possíveis (http://lilypond.org/). 
 
```{r 10- audio 11}
qlily <- quantMerge(snotes, 4, 4, 2)
qlily
```




<!--chapter:end:10-nao-estruturados.Rmd-->

# Pesquisa bibliográfica e Bibliometria


Uma etapa muito importante em qualquer pesquisa científica é fazer o levantamento bibliográfico. 
Temos diversas bases de dados nas quais podemos fazer essa busca, sendo que o PubMed é uma das principais.   
  
  
O número de publicações acadêmicas está aumentando em ritmo acelerado e está se tornando cada vez mais inviável manter-se atualizado com tudo o que está sendo publicado.

Os pesquisadores usam diferentes abordagens qualitativas e quantitativas de revisão de literatura para entender e organizar descobertas anteriores. Entre eles, a bibliometria tem o potencial de introduzir um processo de revisão sistemática, transparente e reprodutível baseado na medição estatística da ciência, dos cientistas ou da atividade científica.

## Pesquisa bibliográfica

Antes de fazer uma análise bibliométrica, é preciso fazer uma pesquisa bibliográfica. Para isso temos que estabelecer um pergunta a ser respondida. Com base no que queremos saber, definimos os descritores com os quais montaremos nosso termo de nossa busca.  

Para auxiliar na escolha dos descritores, podemos usar o DeCS/MeSH (https://decs.bvsalud.org/). Aqui poderemos ver, entre outras coisas:
- a grafia em diferentes idiomas
- os sinônimos

### Termos da busca

Uma vez definidos os descritores, usamos os operadores boleanos AND, OR, NOT para compor o termo de busca.  
Exemplos:
- butyrylcholinesterase OR pseudocholinesterase
- butyrylcholinesterase AND acetylcholinesterase
- butyrylcholinesterase NOT alzheimer
- ((butyrylcholinesterase OR pseudocholinesterase) AND acetylcholinesterase) NOT alzheimer  

Uma vez montado o termo de busca, podemos usá-lo em diferentes bases de dados para fazer nossa pesquisa bibliográfica.  

### Bases de dados

Temos diversas bases de dados. No Brasil temos o Portal de Periódicos CAPES, ao qual temos acesso completo apenas a partir das Universidades.
Portal de Periódicos CAPES (https://www-periodicos-capes-gov-br.ezl.periodicos.capes.gov.br/index.php?)  
Também a partir do Portal de Periódicos CAPES, temos acesso a outras bases como a Web of Science e Scopus.  
Além dessas, temos várias outras, como:  
PubMed (https://pubmed.ncbi.nlm.nih.gov/)
Dimensions (https://app.dimensions.ai/discover/publication
)


## PubMed

No caso do PubMed, é possível fazer a busca diretamente pelo R, utilizando o pacote pubmedR.
Podem ver dicas de utilização do pacote em:
https://cran.r-project.org/web/packages/pubmedR/vignettes/A_Brief_Example.html


Vamos ver um exemplo de utilização, em query montamos o termo de busca e colocamos alguns filtros. Com a função pmQueryTotalCount podemos ver quantos registros a busca retorna:

```{r 11- pubmedR}
library(pubmedR)
query <- "PON1[Title/Abstract] AND english[LA]
AND Journal Article[PT] AND 2018:2023[DP]"

res <- pmQueryTotalCount(query = query, api_key = NULL)

res$total_count
```


Com a função pmApiRequest vamos fazer o download dos dados e com a função pmApi2df transformamos em um dataframe:

```{r 11- pubmedR 2}
D <- pmApiRequest(query = query, limit = 200, api_key = NULL)
df <- pmApi2df(D)
```

São baixados os metadados de cada referência, como título, autores, resumo, revista, ano, etc.

```{r 11- pubmedR 3}
names(df)

df$TI[1]
```

Esses dados, em sua maioria, são caracteres, mas também podemos trabalhar com dados não estruturados no R. O pacote tm tem funções para podermos trabalhar com texto.
Vamos pegar os títulos dos artigos:

```{r 11- pubmedR 4, message=FALSE, warning=FALSE}
library(tm)
library(dplyr)

texto <- iconv(df$TI, to = "UTF-8")
docs <- Corpus(VectorSource(texto))
docs <- docs %>%
  tm_map(removePunctuation) %>%
  tm_map(stripWhitespace)
docs <- tm_map(docs, content_transformer(tolower))
docs <- tm_map(docs, removeWords, stopwords("english"))
```

A seguir criamos um dataframe com as palavras em ordem decrescente de frequência:

```{r 11- pubmedR 5}
dtm <- TermDocumentMatrix(docs) 
matrix <- as.matrix(dtm) 
words <- sort(rowSums(matrix),decreasing=TRUE) 
df2 <- data.frame(word = names(words),freq=words)

head(df2)
```

E com esse dataframe podemos fazer uma nuvem de palavras:

```{r 11- pubmedR 6}
library(wordcloud2)

wordcloud2(data=df2, size=1.6, color='random-dark')
```


## Bibliometria

Para fazer uma análise bibliométrica usamos o pacote bibliometrix
O manual pode ser acessado em https://www.bibliometrix.org/vignettes/Introduction_to_bibliometrix.html
[@aria2017bibliometrix]

Você pode fazer sua busca no Web of Science, depois clique em exportar, arquivo de texto sem formatação, escolha a opção de quais quer salvar e selecione a opção registro completo, referências citadas e clique em exportar. Note que com essa opção é possível salvar 500 referências de cada vez, então se tiver mais de 500 referências, você terá vários arquivos, mas poderá importá-los de uma só vez no R.  

Para fazer a bibliometria usaremos dados baixados, em formato texto, do Web of Science. Para fazer a bibliometria, podemos usar dados de várias bases de dados, mas a Web of Science é a que oferece o maior número de metadados, permitindo utilizar todas as opções de análise.

```{r 11- bibliometria}
library(bibliometrix)

file1 <- c("dados/wos.txt")
M1 <- convert2df(file = file1, dbsource = "wos", format = "plaintext")

```

Podemos ver um resumo da análise:

```{r 11- bibliometria 2}
results <- biblioAnalysis(M1)
summary(results)
```



Podemos ver os principais autores sobre o tema e sua produção ao longo do tempo

```{r 11- bibliometria 4}
topAU <- authorProdOverTime(M1, k = 10, graph = TRUE)
topAU
```

Também podemos ver a co-ocorrência de palavras-chave:

```{r 11- bibliometria 5}
NetMatrix <- biblioNetwork(M1, analysis = "co-occurrences", network = "keywords", sep = ";")
net=networkPlot(NetMatrix, normalize="association", weighted=T, n = 30, Title = "Keyword Co-occurrences", type = "fruchterman", size=T,edgesize = 5,labelsize=0.7)
```

E estruturas conceituais usando as palavras-chave:

```{r 11- bibliometria 6, message=FALSE, warning=FALSE}
CS <- conceptualStructure(M1,field="ID", method="CA", minDegree=4, clust=5, stemming=FALSE, labelsize=10, documents=10)
```


Toda a análise bibliométrica também pode ser feita utilizando shiny, para isso usamos a seguinte função: biblioshiny(), com a qual será aberta uma janela interativa, onde carregamos o arquivo e podemos fazer as análises e gerar os gráficos.  
Para maiores detalhes, consulte a documentação no site https://www.bibliometrix.org/







<!--chapter:end:11-bibliometria.Rmd-->

# R Markdown

Este é um documento R Markdown. Markdown é uma sintaxe de formatação simples para criar documentos HTML, PDF e MS Word. Para obter mais detalhes sobre o uso do R Markdown, consulte <http://rmarkdown.rstudio.com>.

Ao clicar no botão **Knit**, será gerado um documento que inclui tanto o conteúdo quanto a saída de qualquer fragmento de código R incorporado no documento. Você pode incorporar um pedaço de código R como este, no qual vamos carregar os pacotes, os dados, e gerar uma tabela com alguns informações estatísticas:



```{r markdown 1, echo=TRUE, message=FALSE, warning=FALSE}

library(openxlsx)
library(nortest)
library(gridExtra)
dados<-read.xlsx("dados/Data_Cortex_Nuclear.xlsx", sheet = 1, colNames = T)
head(dados)

nomes<-colnames(dados)
tabela1<-data.frame(Proteina=as.character(NA),Media=NA,Mediana=NA, Desvio=NA, Minimo=NA,Maximo=NA,Normalidade=NA)

i<-2
j<-1
for (i in i:78) {
  nome_snp<-nomes[i]
  m<-mean(dados[,i],na.rm=T)
  md<-median(dados[,i],na.rm=T)
  std<-sd(dados[,i],na.rm=T)
  mi<-min(dados[,i],na.rm=T)
  ma<-max(dados[,i],na.rm=T)
  x<-lillie.test(dados[,i])
  p<-x$p.value
  
  tabela1[j,]<-data.frame(Proteina=as.character(nome_snp),Media=m,Mediana=md, Desvio=std, Minimo=mi,Maximo=ma, Normalidade=p)
  
  j<-j+1
}


library(knitr)
library(kableExtra)
library(ggplot2)
```

Agora podemos formatar a tabela e exibir o resulado:  

```{r 12- markdown 2}
kable(tabela1, caption="Tabela 1. Arquivo Cortex: análise descritiva", escape = F)%>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"), full_width = F)
```

## Incluindo gráficos

Você pode incluir um gráfico, como no exemplo abaixo:

```{r 12- markdown 3, echo=FALSE, message=FALSE, warning=FALSE}
ggplot(dados,aes(class,BDNF_N, color=class))+
  geom_boxplot()
```

Veja que com echo = FALSE adicionado ao chunk previne que o código seja incluído no documento gerado.

## Chunk: opções

As opções de chunk são escritas nos cabeçalhos.

Por exemplo:  

{r my-chunk, fig.height=4, dev='jpeg', my-chunk, echo=FALSE}


Uma opção de chunk especial é o rótulo (my-chunk, no exemplo acima). O rótulo para cada chunk é considerado exclusivo dentro do documento. Isso é especialmente importante para nomes de arquivos de cache e plotagem, porque esses nomes de arquivos são baseados em rótulos de chunk.

Execução do código

eval: (TRUE; lógico ou numérico) Se deve executar o código do chunk. Também pode ser um vetor numérico para escolher quais expressões R executar, por exemplo, eval = c(1, 3, 4) avaliará a primeira, terceira e quarta expressões e eval = -(4:5) avaliará todas as expressões, exceto a quarta e a quinta.

Saída de texto

echo: (TRUE; lógico ou numérico) Se o código-fonte deve ser exibido no documento de saída. Além de TRUE/FALSE, que mostra/oculta o código-fonte, também podemos usar um vetor numérico para escolher qual(is) expressão(ões) R ecoará em um pedaço, por exemplo, echo = 2:3 significa ecoar apenas a 2ª e a 3ª expressões , e echo = -4 significa excluir a 4ª expressão.

Outras opções: <https://yihui.org/knitr/options/>

## Formatação

Para formatar um um texto em *itálico*, coloque o texto entre asteriscos. Para **negrito**, coloque entre 2 asteriscos. Para subescrito coloque em sinais de til (H~2~O) e para sobrescrito, coloque entre acentos circunflexos (p^2^).  

Também podemos inserir códigos dentro das linhas. Nesse caso, o código deve ser inserido entre sinais de crase.

```{r markdown 4, echo=TRUE}
x<-c(34,45,12,33,56,74,42,23,45,55)
media<-mean(x)
```

Então em vez de digitar um valor no texto, podemos fazer assim:  
O tamnho da amostra é N = `length(x)`, a média é `mean(x)` e o desvio padrão é `sd(x)`.

Para saber mais:
[@xie2023r]

<!--chapter:end:12-rmarkdown.Rmd-->

`r if (knitr::is_html_output()) '
# References {-}
'`

<!--chapter:end:13-references.Rmd-->

